{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phunc20/.virtualenvs/tf2.2.0-torch1.5.1/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "from array import *\n",
    "import os\n",
    "import math\n",
    "#from random import randrange\n",
    "import random\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.models import model_from_json\n",
    "#from keras.layers import Dense, Activation\n",
    "#from keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes in GAME_SOCKET_DUMMY.py\n",
    "class ObstacleInfo:\n",
    "    # initial energy for obstacles: Land (key = 0): -1, Forest(key = -1): 0 (random), Trap(key = -2): -10, Swamp (key = -3): -5\n",
    "    types = {0: -1, -1: 0, -2: -10, -3: -5}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.type = 0\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.value = 0\n",
    "        \n",
    "class GoldInfo:\n",
    "    def __init__(self):\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.amount = 0\n",
    "\n",
    "    def loads(self, data):\n",
    "        golds = []\n",
    "        for gd in data:\n",
    "            g = GoldInfo()\n",
    "            g.posx = gd[\"posx\"]\n",
    "            g.posy = gd[\"posy\"]\n",
    "            g.amount = gd[\"amount\"]\n",
    "            golds.append(g)\n",
    "        return golds\n",
    "\n",
    "class PlayerInfo:\n",
    "    STATUS_PLAYING = 0\n",
    "    STATUS_ELIMINATED_WENT_OUT_MAP = 1\n",
    "    STATUS_ELIMINATED_OUT_OF_ENERGY = 2\n",
    "    STATUS_ELIMINATED_INVALID_ACTION = 3\n",
    "    STATUS_STOP_EMPTY_GOLD = 4\n",
    "    STATUS_STOP_END_STEP = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.playerId = id\n",
    "        self.score = 0\n",
    "        self.energy = 0\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.lastAction = -1\n",
    "        self.status = PlayerInfo.STATUS_PLAYING\n",
    "        self.freeCount = 0\n",
    "\n",
    "class GameInfo:\n",
    "    def __init__(self):\n",
    "        self.numberOfPlayers = 1\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.steps = 100\n",
    "        self.golds = []\n",
    "        self.obstacles = []\n",
    "\n",
    "    def loads(self, data):\n",
    "        m = GameInfo()\n",
    "        m.width = data[\"width\"]\n",
    "        m.height = data[\"height\"]\n",
    "        m.golds = GoldInfo().loads(data[\"golds\"])\n",
    "        m.obstacles = data[\"obstacles\"]\n",
    "        m.numberOfPlayers = data[\"numberOfPlayers\"]\n",
    "        m.steps = data[\"steps\"]\n",
    "        return m\n",
    "\n",
    "class UserMatch:\n",
    "    def __init__(self):\n",
    "        self.playerId = 1\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.energy = 50\n",
    "        self.gameinfo = GameInfo()\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "class StepState:\n",
    "    def __init__(self):\n",
    "        self.players = []\n",
    "        self.golds = []\n",
    "        self.changedObstacles = []\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main class in GAME_SOCKET_DUMMY.py\n",
    "class GameSocket:\n",
    "    bog_energy_chain = {-5: -20, -20: -40, -40: -100, -100: -100}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stepCount = 0\n",
    "        self.maxStep = 0\n",
    "        self.mapdir = \"Maps\"  # where to load all pre-defined maps\n",
    "        self.mapid = \"\"\n",
    "        self.userMatch = UserMatch()\n",
    "        self.user = PlayerInfo(1)\n",
    "        self.stepState = StepState()\n",
    "        self.maps = {}  # key: map file name, value: file content\n",
    "        self.map = []  # running map info: 0->Land, -1->Forest, -2->Trap, -3:Swamp, >0:Gold\n",
    "        self.energyOnMap = []  # self.energyOnMap[x][y]: <0, amount of energy which player will consume if it move into (x,y)\n",
    "        self.E = 50\n",
    "        self.resetFlag = True\n",
    "        self.craftUsers = []  # players that craft at current step - for calculating amount of gold\n",
    "        self.bots = []\n",
    "        self.craftMap = {}  # cells that players craft at current step, key: x_y, value: number of players that craft at (x,y)\n",
    "\n",
    "    def init_bots(self):\n",
    "        self.bots = [Bot1(2), Bot2(3), Bot3(4)]  # use bot1(id=2), bot2(id=3), bot3(id=4)\n",
    "        #for (bot) in self.bots:  # at the beginning, all bots will have same position, energy as player\n",
    "        for bot in self.bots:  # at the beginning, all bots will have same position, energy as player\n",
    "            bot.info.posx = self.user.posx\n",
    "            bot.info.posy = self.user.posy\n",
    "            bot.info.energy = self.user.energy\n",
    "            bot.info.lastAction = -1\n",
    "            bot.info.status = PlayerInfo.STATUS_PLAYING\n",
    "            bot.info.score = 0\n",
    "            self.stepState.players.append(bot.info)\n",
    "        self.userMatch.gameinfo.numberOfPlayers = len(self.stepState.players)\n",
    "        #print(\"numberOfPlayers: \", self.userMatch.gameinfo.numberOfPlayers)\n",
    "\n",
    "    def reset(self, requests):  # load new game by given request: [map id (filename), posx, posy, initial energy]\n",
    "        # load new map\n",
    "        self.reset_map(requests[0])\n",
    "        self.userMatch.posx = int(requests[1])\n",
    "        self.userMatch.posy = int(requests[2])\n",
    "        self.userMatch.energy = int(requests[3])\n",
    "        self.userMatch.gameinfo.steps = int(requests[4])\n",
    "        self.maxStep = self.userMatch.gameinfo.steps\n",
    "\n",
    "        # init data for players\n",
    "        self.user.posx = self.userMatch.posx  # in\n",
    "        self.user.posy = self.userMatch.posy\n",
    "        self.user.energy = self.userMatch.energy\n",
    "        self.user.status = PlayerInfo.STATUS_PLAYING\n",
    "        self.user.score = 0\n",
    "        self.stepState.players = [self.user]\n",
    "        self.E = self.userMatch.energy\n",
    "        self.resetFlag = True\n",
    "        self.init_bots()\n",
    "        self.stepCount = 0\n",
    "\n",
    "    def reset_map(self, id):  # load map info\n",
    "        self.mapId = id\n",
    "        self.map = json.loads(self.maps[self.mapId])\n",
    "        self.userMatch = self.map_info(self.map)\n",
    "        self.stepState.golds = self.userMatch.gameinfo.golds\n",
    "        self.map = json.loads(self.maps[self.mapId])\n",
    "        self.energyOnMap = json.loads(self.maps[self.mapId])\n",
    "        for x in range(len(self.map)):\n",
    "            for y in range(len(self.map[x])):\n",
    "                if self.map[x][y] > 0:  # gold\n",
    "                    self.energyOnMap[x][y] = -4\n",
    "                else:  # obstacles\n",
    "                    self.energyOnMap[x][y] = ObstacleInfo.types[self.map[x][y]]\n",
    "\n",
    "    def connect(self): # simulate player's connect request\n",
    "        print(\"Connected to server.\")\n",
    "        for mapid in range(len(Maps)):\n",
    "            filename = \"map\" + str(mapid)\n",
    "            print(\"Found: \" + filename)\n",
    "            self.maps[filename] = str(Maps[mapid])\n",
    "\n",
    "    def map_info(self, map):  # get map info\n",
    "        # print(map)\n",
    "        userMatch = UserMatch()\n",
    "        userMatch.gameinfo.height = len(map)\n",
    "        userMatch.gameinfo.width = len(map[0])\n",
    "        i = 0\n",
    "        while i < len(map):\n",
    "            j = 0\n",
    "            while j < len(map[i]):\n",
    "                if map[i][j] > 0:  # gold\n",
    "                    g = GoldInfo()\n",
    "                    g.posx = j\n",
    "                    g.posy = i\n",
    "                    g.amount = map[i][j]\n",
    "                    userMatch.gameinfo.golds.append(g)\n",
    "                else:  # obstacles\n",
    "                    o = ObstacleInfo()\n",
    "                    o.posx = j\n",
    "                    o.posy = i\n",
    "                    o.type = -map[i][j]\n",
    "                    o.value = ObstacleInfo.types[map[i][j]]\n",
    "                    userMatch.gameinfo.obstacles.append(o)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        return userMatch\n",
    "\n",
    "    def receive(self):  # send data to player (simulate player's receive request)\n",
    "        if self.resetFlag:  # for the first time -> send game info\n",
    "            self.resetFlag = False\n",
    "            data = self.userMatch.to_json()\n",
    "            for (bot) in self.bots:\n",
    "                bot.new_game(data)\n",
    "            # print(data)\n",
    "            return data\n",
    "        else:  # send step state\n",
    "            self.stepCount = self.stepCount + 1\n",
    "            if self.stepCount >= self.maxStep:\n",
    "                for player in self.stepState.players:\n",
    "                    player.status = PlayerInfo.STATUS_STOP_END_STEP\n",
    "            data = self.stepState.to_json()\n",
    "            #for (bot) in self.bots:  # update bots' state\n",
    "            for bot in self.bots:  # update bots' state\n",
    "                bot.new_state(data)\n",
    "            # print(data)\n",
    "            return data\n",
    "\n",
    "    def send(self, message):  # receive message from player (simulate send request from player)\n",
    "        if message.isnumeric():  # player send action\n",
    "            self.resetFlag = False\n",
    "            self.stepState.changedObstacles = []\n",
    "            action = int(message)\n",
    "            # print(\"Action = \", action)\n",
    "            self.user.lastAction = action\n",
    "            self.craftUsers = []\n",
    "            self.step_action(self.user, action)\n",
    "            for bot in self.bots:\n",
    "                if bot.info.status == PlayerInfo.STATUS_PLAYING:\n",
    "                    action = bot.next_action()\n",
    "                    bot.info.lastAction = action\n",
    "                    # print(\"Bot Action: \", action)\n",
    "                    self.step_action(bot.info, action)\n",
    "            self.action_5_craft()\n",
    "            for c in self.stepState.changedObstacles:\n",
    "                self.map[c[\"posy\"]][c[\"posx\"]] = -c[\"type\"]\n",
    "                self.energyOnMap[c[\"posy\"]][c[\"posx\"]] = c[\"value\"]\n",
    "\n",
    "        else:  # reset game\n",
    "            requests = message.split(\",\")\n",
    "            print(\"Reset game: \", requests[:3], end='')\n",
    "            self.reset(requests)\n",
    "\n",
    "    def step_action(self, user, action):\n",
    "        switcher = {\n",
    "            0: self.action_0_left,\n",
    "            1: self.action_1_right,\n",
    "            2: self.action_2_up,\n",
    "            3: self.action_3_down,\n",
    "            4: self.action_4_free,\n",
    "            5: self.action_5_craft_pre\n",
    "        }\n",
    "        func = switcher.get(action, self.invalidAction)\n",
    "        func(user)\n",
    "\n",
    "    def action_5_craft_pre(self, user):  # collect players who craft at current step\n",
    "        user.freeCount = 0\n",
    "        if self.map[user.posy][user.posx] <= 0:  # craft at the non-gold cell\n",
    "            user.energy -= 10\n",
    "            if user.energy <= 0:\n",
    "                user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "                user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            user.energy -= 5\n",
    "            if user.energy > 0:\n",
    "                self.craftUsers.append(user)\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                if key in self.craftMap:\n",
    "                    count = self.craftMap[key]\n",
    "                    self.craftMap[key] = count + 1\n",
    "                else:\n",
    "                    self.craftMap[key] = 1\n",
    "            else:\n",
    "                user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "                user.lastAction = 6 #eliminated\n",
    "\n",
    "    def action_0_left(self, user):  # user go left\n",
    "        user.freeCount = 0\n",
    "        user.posx = user.posx - 1\n",
    "        if user.posx < 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_1_right(self, user):  # user go right\n",
    "        user.freeCount = 0\n",
    "        user.posx = user.posx + 1\n",
    "        if user.posx >= self.userMatch.gameinfo.width:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_2_up(self, user):  # user go up\n",
    "        user.freeCount = 0\n",
    "        user.posy = user.posy - 1\n",
    "        if user.posy < 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_3_down(self, user):  # user go right\n",
    "        user.freeCount = 0\n",
    "        user.posy = user.posy + 1\n",
    "        if user.posy >= self.userMatch.gameinfo.height:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_4_free(self, user):  # user free\n",
    "        user.freeCount += 1\n",
    "        if user.freeCount == 1:\n",
    "            user.energy += int(self.E / 4)\n",
    "        elif user.freeCount == 2:\n",
    "            user.energy += int(self.E / 3)\n",
    "        elif user.freeCount == 3:\n",
    "            user.energy += int(self.E / 2)\n",
    "        else:\n",
    "            user.energy = self.E\n",
    "        if user.energy > self.E:\n",
    "            user.energy = self.E\n",
    "\n",
    "    def action_5_craft(self):\n",
    "        craftCount = len(self.craftUsers)\n",
    "        # print (\"craftCount\",craftCount)\n",
    "        if (craftCount > 0):\n",
    "            for user in self.craftUsers:\n",
    "                x = user.posx\n",
    "                y = user.posy\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                c = self.craftMap[key]\n",
    "                m = min(math.ceil(self.map[y][x] / c), 50)\n",
    "                user.score += m\n",
    "                # print (\"user\", user.playerId, m)\n",
    "            for user in self.craftUsers:\n",
    "                x = user.posx\n",
    "                y = user.posy\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                if key in self.craftMap:\n",
    "                    c = self.craftMap[key]\n",
    "                    del self.craftMap[key]\n",
    "                    m = min(math.ceil(self.map[y][x] / c), 50)\n",
    "                    self.map[y][x] -= m * c\n",
    "                    if self.map[y][x] < 0:\n",
    "                        self.map[y][x] = 0\n",
    "                        self.energyOnMap[y][x] = ObstacleInfo.types[0]\n",
    "                    for g in self.stepState.golds:\n",
    "                        if g.posx == x and g.posy == y:\n",
    "                            g.amount = self.map[y][x]\n",
    "                            if g.amount == 0:\n",
    "                                self.stepState.golds.remove(g)\n",
    "                                self.add_changed_obstacle(x, y, 0, ObstacleInfo.types[0])\n",
    "                                if len(self.stepState.golds) == 0:\n",
    "                                    for player in self.stepState.players:\n",
    "                                        player.status = PlayerInfo.STATUS_STOP_EMPTY_GOLD\n",
    "                            break;\n",
    "            self.craftMap = {}\n",
    "\n",
    "    def invalidAction(self, user):\n",
    "        user.status = PlayerInfo.STATUS_ELIMINATED_INVALID_ACTION\n",
    "        user.lastAction = 6 #eliminated\n",
    "\n",
    "    def go_to_pos(self, user):  # player move to cell(x,y)\n",
    "        if self.map[user.posy][user.posx] == -1:\n",
    "            user.energy -= randrange(16) + 5\n",
    "        elif self.map[user.posy][user.posx] == 0:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "        elif self.map[user.posy][user.posx] == -2:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "            self.add_changed_obstacle(user.posx, user.posy, 0, ObstacleInfo.types[0])\n",
    "        elif self.map[user.posy][user.posx] == -3:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "            self.add_changed_obstacle(user.posx, user.posy, 3,\n",
    "                                      self.bog_energy_chain[self.energyOnMap[user.posy][user.posx]])\n",
    "        else:\n",
    "            user.energy -= 4\n",
    "        if user.energy <= 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "            user.lastAction = 6 #eliminated\n",
    "\n",
    "    def add_changed_obstacle(self, x, y, t, v):\n",
    "        added = False\n",
    "        for o in self.stepState.changedObstacles:\n",
    "            if o[\"posx\"] == x and o[\"posy\"] == y:\n",
    "                added = True\n",
    "                break\n",
    "        if added == False:\n",
    "            o = {}\n",
    "            o[\"posx\"] = x\n",
    "            o[\"posy\"] = y\n",
    "            o[\"type\"] = t\n",
    "            o[\"value\"] = v\n",
    "            self.stepState.changedObstacles.append(o)\n",
    "\n",
    "    def close(self):\n",
    "        print(\"Close socket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot1\n",
    "class Bot1:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = self.ACTION_GO_UP\n",
    "            if self.info.posy % 2 == 0:\n",
    "                if self.info.posx < self.state.mapInfo.max_x:\n",
    "                    action = self.ACTION_GO_RIGHT\n",
    "            else:\n",
    "                if self.info.posx > 0:\n",
    "                    action = self.ACTION_GO_LEFT\n",
    "                else:\n",
    "                    action = self.ACTION_GO_DOWN\n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot2\n",
    "class Bot2:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = np.random.randint(0, 4)            \n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot3\n",
    "class Bot3:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = self.ACTION_GO_LEFT\n",
    "            if self.info.posx % 2 == 0:\n",
    "                if self.info.posy < self.state.mapInfo.max_y:\n",
    "                    action = self.ACTION_GO_DOWN\n",
    "            else:\n",
    "                if self.info.posy > 0:\n",
    "                    action = self.ACTION_GO_UP\n",
    "                else:\n",
    "                    action = self.ACTION_GO_RIGHT            \n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinerState.py\n",
    "def str_2_json(str):\n",
    "    return json.loads(str, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class MapInfo:\n",
    "    def __init__(self):\n",
    "        self.max_x = 0 #Width of the map\n",
    "        self.max_y = 0 #Height of the map\n",
    "        self.golds = [] #List of the golds in the map\n",
    "        self.obstacles = []\n",
    "        self.numberOfPlayers = 0\n",
    "        self.maxStep = 0 #The maximum number of step is set for this map\n",
    "\n",
    "    def init_map(self, gameInfo):\n",
    "        #Initialize the map at the begining of each episode\n",
    "        self.max_x = gameInfo[\"width\"] - 1\n",
    "        self.max_y = gameInfo[\"height\"] - 1\n",
    "        self.golds = gameInfo[\"golds\"]\n",
    "        self.obstacles = gameInfo[\"obstacles\"]\n",
    "        self.maxStep = gameInfo[\"steps\"]\n",
    "        self.numberOfPlayers = gameInfo[\"numberOfPlayers\"]\n",
    "\n",
    "    def update(self, golds, changedObstacles):\n",
    "        #Update the map after every step\n",
    "        self.golds = golds\n",
    "        for cob in changedObstacles:\n",
    "            newOb = True\n",
    "            for ob in self.obstacles:\n",
    "                if cob[\"posx\"] == ob[\"posx\"] and cob[\"posy\"] == ob[\"posy\"]:\n",
    "                    newOb = False\n",
    "                    #print(\"cell(\", cob[\"posx\"], \",\", cob[\"posy\"], \") change type from: \", ob[\"type\"], \" -> \",\n",
    "                    #      cob[\"type\"], \" / value: \", ob[\"value\"], \" -> \", cob[\"value\"])\n",
    "                    ob[\"type\"] = cob[\"type\"]\n",
    "                    ob[\"value\"] = cob[\"value\"]\n",
    "                    break\n",
    "            if newOb:\n",
    "                self.obstacles.append(cob)\n",
    "                #print(\"new obstacle: \", cob[\"posx\"], \",\", cob[\"posy\"], \", type = \", cob[\"type\"], \", value = \",\n",
    "                #      cob[\"value\"])\n",
    "\n",
    "    def get_min_x(self):\n",
    "        return min([cell[\"posx\"] for cell in self.golds])\n",
    "\n",
    "    def get_max_x(self):\n",
    "        return max([cell[\"posx\"] for cell in self.golds])\n",
    "\n",
    "    def get_min_y(self):\n",
    "        return min([cell[\"posy\"] for cell in self.golds])\n",
    "\n",
    "    def get_max_y(self):\n",
    "        return max([cell[\"posy\"] for cell in self.golds])\n",
    "\n",
    "    def is_row_has_gold(self, y):\n",
    "        return y in [cell[\"posy\"] for cell in self.golds]\n",
    "\n",
    "    def is_column_has_gold(self, x):\n",
    "        return x in [cell[\"posx\"] for cell in self.golds]\n",
    "\n",
    "    def gold_amount(self, x, y): #Get the amount of golds at cell (x,y)\n",
    "        for cell in self.golds:\n",
    "            if x == cell[\"posx\"] and y == cell[\"posy\"]:\n",
    "                return cell[\"amount\"]\n",
    "        return 0 \n",
    "\n",
    "    def get_obstacle(self, x, y):  # Get the kind of the obstacle at cell(x,y)\n",
    "        for cell in self.obstacles:\n",
    "            if x == cell[\"posx\"] and y == cell[\"posy\"]:\n",
    "                return cell[\"type\"]\n",
    "        return -1  # No obstacle at the cell (x,y)\n",
    "\n",
    "\n",
    "class State:\n",
    "    STATUS_PLAYING = 0\n",
    "    STATUS_ELIMINATED_WENT_OUT_MAP = 1\n",
    "    STATUS_ELIMINATED_OUT_OF_ENERGY = 2\n",
    "    STATUS_ELIMINATED_INVALID_ACTION = 3\n",
    "    STATUS_STOP_EMPTY_GOLD = 4\n",
    "    STATUS_STOP_END_STEP = 5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.end = False\n",
    "        self.score = 0\n",
    "        self.lastAction = None\n",
    "        self.id = 0\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.energy = 0\n",
    "        self.mapInfo = MapInfo()\n",
    "        self.players = []\n",
    "        self.stepCount = 0\n",
    "        self.status = State.STATUS_PLAYING\n",
    "\n",
    "    def init_state(self, data): #parse data from server into object\n",
    "        game_info = str_2_json(data)\n",
    "        self.end = False\n",
    "        self.score = 0\n",
    "        self.lastAction = None\n",
    "        self.id = game_info[\"playerId\"]\n",
    "        self.x = game_info[\"posx\"]\n",
    "        self.y = game_info[\"posy\"]\n",
    "        self.energy = game_info[\"energy\"]\n",
    "        self.mapInfo.init_map(game_info[\"gameinfo\"])\n",
    "        self.stepCount = 0\n",
    "        self.status = State.STATUS_PLAYING\n",
    "        self.players = [{\"playerId\": 2, \"posx\": self.x, \"posy\": self.y},\n",
    "                        {\"playerId\": 3, \"posx\": self.x, \"posy\": self.y},\n",
    "                        {\"playerId\": 4, \"posx\": self.x, \"posy\": self.y}]\n",
    "\n",
    "    def update_state(self, data):\n",
    "        new_state = str_2_json(data)\n",
    "        for player in new_state[\"players\"]:\n",
    "            if player[\"playerId\"] == self.id:\n",
    "                self.x = player[\"posx\"]\n",
    "                self.y = player[\"posy\"]\n",
    "                self.energy = player[\"energy\"]\n",
    "                self.score = player[\"score\"]\n",
    "                self.lastAction = player[\"lastAction\"]\n",
    "                self.status = player[\"status\"]\n",
    "\n",
    "        self.mapInfo.update(new_state[\"golds\"], new_state[\"changedObstacles\"])\n",
    "        self.players = new_state[\"players\"]\n",
    "        for i in range(len(self.players), 4, 1):\n",
    "            self.players.append({\"playerId\": i, \"posx\": self.x, \"posy\": self.y})\n",
    "        self.stepCount = self.stepCount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinerEnv.py\n",
    "TreeID = 1\n",
    "TrapID = 2\n",
    "SwampID = 3\n",
    "class MinerEnv:\n",
    "    def __init__(self):\n",
    "        self.socket = GameSocket()\n",
    "        self.state = State()\n",
    "        \n",
    "        self.score_pre = self.state.score#Storing the last score for designing the reward function\n",
    "\n",
    "    def start(self): #connect to server\n",
    "        self.socket.connect()\n",
    "\n",
    "    def end(self): #disconnect server\n",
    "        self.socket.close()\n",
    "\n",
    "    def send_map_info(self, request):#tell server which map to run\n",
    "        self.socket.send(request)\n",
    "\n",
    "    def reset(self): #start new game\n",
    "        try:\n",
    "            message = self.socket.receive() #receive game info from server\n",
    "            self.state.init_state(message) #init state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def step(self, action): #step process\n",
    "        self.socket.send(action) #send action to server\n",
    "        try:\n",
    "            message = self.socket.receive() #receive new state from server\n",
    "            self.state.update_state(message) #update to local state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # Functions are customized by client\n",
    "    def get_state(self):\n",
    "        # Building the map\n",
    "        #view = np.zeros([self.state.mapInfo.max_x + 1, self.state.mapInfo.max_y + 1], dtype=int)\n",
    "        view = np.zeros([self.state.mapInfo.max_y + 1, self.state.mapInfo.max_x + 1], dtype=int)\n",
    "        for x in range(self.state.mapInfo.max_x + 1):\n",
    "            for y in range(self.state.mapInfo.max_y + 1):\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TreeID:  # Tree\n",
    "                    view[y, x] = -TreeID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TrapID:  # Trap\n",
    "                    view[y, x] = -TrapID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == SwampID: # Swamp\n",
    "                    view[y, x] = -SwampID\n",
    "                if self.state.mapInfo.gold_amount(x, y) > 0:\n",
    "                    view[y, x] = self.state.mapInfo.gold_amount(x, y)\n",
    "\n",
    "        DQNState = view.flatten().tolist() #Flattening the map matrix to a vector\n",
    "        \n",
    "        # Add position and energy of agent to the DQNState\n",
    "        DQNState.append(self.state.x)\n",
    "        DQNState.append(self.state.y)\n",
    "        DQNState.append(self.state.energy)\n",
    "        #Add position of bots \n",
    "        for player in self.state.players:\n",
    "            if player[\"playerId\"] != self.state.id:\n",
    "                DQNState.append(player[\"posx\"])\n",
    "                DQNState.append(player[\"posy\"])\n",
    "                \n",
    "        #Convert the DQNState from list to array for training\n",
    "        DQNState = np.array(DQNState)\n",
    "\n",
    "        return DQNState\n",
    "\n",
    "    def get_reward(self):\n",
    "        # Calculate reward\n",
    "        reward = 0\n",
    "        score_action = self.state.score - self.score_pre\n",
    "        self.score_pre = self.state.score\n",
    "        if score_action > 0:\n",
    "            #If the DQN agent crafts golds, then it should obtain a positive reward (equal score_action)\n",
    "            #reward += score_action\n",
    "            reward += score_action*5\n",
    "            \n",
    "        ##If the DQN agent crashs into obstacels (Tree, Trap, Swamp), then it should be punished by a negative reward\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == TreeID:  # Tree\n",
    "        #    reward -= TreeID\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == TrapID:  # Trap\n",
    "        #    reward -= TrapID\n",
    "        if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == SwampID:  # Swamp\n",
    "            reward -= SwampID\n",
    "            if self.state.lastAction == 4:\n",
    "                reward -= 40\n",
    "\n",
    "        # If out of the map, then the DQN agent should be punished by a larger nagative reward.\n",
    "        if self.state.status == State.STATUS_ELIMINATED_WENT_OUT_MAP:\n",
    "            #if self.state.stepCount < 50:\n",
    "            #    reward += -5*(50 - self.state.stepCount)\n",
    "            reward += -50\n",
    "            \n",
    "        #Run out of energy, then the DQN agent should be punished by a larger nagative reward.\n",
    "        if self.state.status == State.STATUS_ELIMINATED_OUT_OF_ENERGY:\n",
    "            if self.state.stepCount < 50:\n",
    "                reward += -(50 - self.state.stepCount)\n",
    "                if self.state.lastAction != 4:\n",
    "                    # 4 is taking a rest\n",
    "                    reward += -10\n",
    "        \n",
    "        # control comes to here \\implies our agent is not dead yet\n",
    "        if self.state.status == State.STATUS_PLAYING:\n",
    "            if self.state.energy >= 45 and self.state.lastAction == 4:\n",
    "                reward -= 30\n",
    "        # print (\"reward\",reward)\n",
    "        return reward\n",
    "\n",
    "    def check_terminate(self):\n",
    "        #Checking the status of the game\n",
    "        #it indicates the game ends or is playing\n",
    "        return self.state.status != State.STATUS_PLAYING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_replay_len = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "input_shape = [198] # == env.observation_space.shape\n",
    "n_outputs = 6 # == env.action_space.n\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation=\"elu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(64, activation=\"elu\"),\n",
    "    keras.layers.Dense(n_outputs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon=0, n_actions=6):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_actions)\n",
    "    else:\n",
    "        Q_values = model.predict(state[np.newaxis])\n",
    "        return np.argmax(Q_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3,4))[np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3,4))[:, np.newaxis, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "replay_memory = deque(maxlen=max_replay_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_experiences(batch_size):\n",
    "    indices = np.random.randint(len(replay_memory), size=batch_size)\n",
    "    batch = [replay_memory[index] for index in indices]\n",
    "    states, actions, rewards, next_states, dones = [\n",
    "        np.array([experience[field_index] for experience in batch])\n",
    "        for field_index in range(5)]\n",
    "    return states, actions, rewards, next_states, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, state, epsilon):\n",
    "    action = epsilon_greedy_policy(state, epsilon)\n",
    "    #next_state, reward, done, info = env.step(action)\n",
    "    env.step(str(action))\n",
    "    next_state = env.get_state()\n",
    "    reward = env.get_reward()\n",
    "    done = env.check_terminate()\n",
    "    replay_memory.append((state, action, reward, next_state, done))\n",
    "    return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "discount_rate = 0.95\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "def training_step(batch_size):\n",
    "    experiences = sample_experiences(batch_size)\n",
    "    states, actions, rewards, next_states, dones = experiences\n",
    "    next_Q_values = model.predict(next_states)\n",
    "    max_next_Q_values = np.max(next_Q_values, axis=1)\n",
    "    target_Q_values = rewards + (1 - dones) * discount_rate * max_next_Q_values\n",
    "    mask = tf.one_hot(actions, n_outputs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_Q_values = model(states)\n",
    "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
    "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.seed(42)\n",
    "np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "rewards = [] \n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Maps\n",
    "#This function is used to create 05 maps instead of loading them from Maps folder in the local\n",
    "def CreateMaps():\n",
    "    map0 = [\n",
    "      [0,  0,  -2,  100,  0,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  0,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  0,  0,  0,  -1,  -1,  -1,  0, 0,  100,  0,  0,  0,  0,  50,  -2,  0,0],\n",
    "      [0,  0,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  50, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  200,  -2,  -2,  300,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  0,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  -1,  -1,  0,  0,  -1,  -1,  0,  0,  700,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 0,100],\n",
    "      [0,  0, 0, 500,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  0,  400,  -2,  -1,  -1,  500,  0,  -2,  0,  -3,  100,  0, 0,0]\n",
    "    ]\n",
    "    map1 = [\n",
    "      [0,  0,  -2,  0,  0,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  100, 0,  0,  -3,  -1,  0,  -2,  100,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  0,  0,  0,  -1,  -1,  -1,  0, 0,  0,  0,  0,  0,  50,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  50, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  300,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [500,  -1,  -1,  0,  0,  -1,  -1,  0,  700,  0,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 0,0],\n",
    "      [0,  0, 0, 0,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  100,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "    ]\n",
    "    map2 = [\n",
    "      [0,  0,  -2,  0,  0,  0,  -1,  -1,  -3,  0,  100,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  0,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0 ],\n",
    "      [0,  0,  -1,  0,  0,  0,  100,  -1,  -1,  -1,  0, 0,  50,  0,  0,  0,  50,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  0, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0, 300,  0,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  -1,  -1,  0,  0,  -1,  -1,  700,  0,  0,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 0,0],\n",
    "      [0,  0, 0, 0,  0,  500,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  700,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "    ]\n",
    "    map3 = [\n",
    "      [0,  0,  -2,  0,  0,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  0,  0,  100,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  100,  0,  0,  -1,  -1,  -1,  0, 0,  0,  0,  50,  0,  50,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  0, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  0,  0,  300,  -3,  0,  700,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  -1,  -1,  0,  0,  -1,  -1,  0,  0,  0,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 100,0],\n",
    "      [500,  0, 0, 0,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "\n",
    "    ]\n",
    "    map4 = [\n",
    "      [0,  0,  -2,  0,  100,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  100,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  0,  0,  0,  -1,  -1,  -1,  0, 0,  0,  0,  50,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  0, -2,  0,  50,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  300,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [500,  -1,  -1,  0,  0,  -1,  -1,  0,  0,  700,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 100,0],\n",
    "      [0,  0, 0, 0,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "    ]\n",
    "    Maps = (map0,map1,map2,map3,map4)\n",
    "    return Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_over_reason = (\n",
    "    \"playing\",\n",
    "    \"went_out_map\",\n",
    "    \"out_of_energy\",\n",
    "    \"invalid_action\",\n",
    "    \"no_more_gold\",\n",
    "    \"no_more_step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maps = CreateMaps()\n",
    "env = MinerEnv() # Creating a communication environment between the DQN model and the game environment\n",
    "env.start() # Connect to the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 10_000\n",
    "n_epsilon_decay = int(n_episodes*.7)\n",
    "n_max_steps = 100\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    mapID = np.random.randint(0, 5)\n",
    "    posID_x = np.random.randint(MAP_MAX_X) \n",
    "    posID_y = np.random.randint(MAP_MAX_Y)\n",
    "    request = \"map{},{},{},50,100\".format(mapID, posID_x, posID_y)\n",
    "    env.send_map_info(request)\n",
    "    #obs = env.reset()\n",
    "    env.reset()\n",
    "    obs = env.get_state()\n",
    "    for step in range(n_max_steps):\n",
    "        epsilon = max(1 - episode / n_epsilon_decay, 0.01)\n",
    "        obs, reward, done = play_one_step(env, obs, epsilon)\n",
    "        if done:\n",
    "            break\n",
    "    rewards.append(reward)\n",
    "    if reward > best_score:\n",
    "        best_weights = model.get_weights()\n",
    "        best_score = reward\n",
    "    #print(\"\\rEpisode: {}, Steps: {}, eps: {:.3f}\".format(episode, step + 1, epsilon), end=\"\")\n",
    "    print(\"Episode: {}, Steps: {}, eps: {:.3f}\".format(episode, step + 1, epsilon), end=\"\\r\")\n",
    "    if episode > 1000:\n",
    "        training_step(batch_size)\n",
    "\n",
    "model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#DQN Algorithm-Main\n",
    "#Create header for saving DQN learning file\n",
    "'''now = datetime.datetime.now()\n",
    "header = [\"Ep\",\"Step\", \"Reward\",\"Total_reward\",\"Action\",\"Epsilon\",\"Done\",\"Termination_Code\"]\n",
    "filename = \"Data/data_\" + now.strftime(\"%Y%m%d-%H%M\") + \".csv\"\n",
    "with open(filename, 'w') as f:\n",
    "    pd.DataFrame(columns = header).to_csv(f,encoding='utf-8', index=False, header = True)'''\n",
    "\n",
    "# Parameters for training a DQN model\n",
    "N_EPISODES = 99_000\n",
    "MAX_STEP = 100   #The number of steps for each episode\n",
    "BATCH_SIZE = 32   #The number of experiences for each replay \n",
    "MEMORY_SIZE = 100_000 #The size of the batch for storing experiences\n",
    "SAVE_NETWORK = 150  # After this number of episodes, the DQN model is saved for testing later. \n",
    "INITIAL_REPLAY_SIZE = 1000 #The number of experiences are stored in the memory batch before starting replaying\n",
    "INPUT_DIMS = 198 #The number of input values for the DQN model\n",
    "N_ACTIONS = 6  #The number of actions output from the DQN model\n",
    "MAP_MAX_X = 21 #Width of the Map\n",
    "MAP_MAX_Y = 9  #Height of the Map\n",
    "\n",
    "# Initialize network and memory\n",
    "DQNAgent = DQN(INPUT_DIMS, N_ACTIONS)\n",
    "memory = Memory(MEMORY_SIZE)\n",
    "\n",
    "# Initialize environment\n",
    "Maps = CreateMaps()\n",
    "minerEnv = MinerEnv() # Creating a communication environment between the DQN model and the game environment\n",
    "minerEnv.start() # Connect to the game\n",
    "\n",
    "train = False # The variable is used to indicate that the replay starts, and the epsilon starts decrease.\n",
    "for episode_i in range(N_EPISODES):\n",
    "    try:\n",
    "        mapID = np.random.randint(0, 5)\n",
    "        # Initial position of the DQN agent\n",
    "        posID_x = np.random.randint(MAP_MAX_X) \n",
    "        posID_y = np.random.randint(MAP_MAX_Y)\n",
    "\n",
    "        request = (\"map\" + str(mapID) + \",\" + str(posID_x) + \",\" + str(posID_y) + \",50,100\") \n",
    "        #request = \"map{},{},{},50,100\".format(mapID, posID_x, posID_y)\n",
    "        # (?2) 50, 100? What are these numbers?\n",
    "        minerEnv.send_map_info(request)\n",
    "\n",
    "        minerEnv.reset()\n",
    "        s = minerEnv.get_state()\n",
    "        total_reward = 0\n",
    "        terminate = False # This indicates whether the episode has ended\n",
    "        maxStep = minerEnv.state.mapInfo.maxStep # Get the maximum number of steps for each episode in training\n",
    "        # Start an episde for training\n",
    "        for step in range(0, maxStep):\n",
    "            action = DQNAgent.act(s)  # Getting an action from the DQN model from the state (s)\n",
    "            minerEnv.step(str(action))  # Performing the action in order to obtain the new state\n",
    "            s_next = minerEnv.get_state()  # Getting a new state\n",
    "            reward = minerEnv.get_reward()  # Getting a reward\n",
    "            terminate = minerEnv.check_terminate()  # Checking the end status of the episode\n",
    "             \n",
    "            # Add this transition to the memory batch\n",
    "            memory.push(s, action, reward, terminate, s_next)\n",
    "\n",
    "            # Sample batch memory to train network\n",
    "            if (memory.length > INITIAL_REPLAY_SIZE):\n",
    "                #If there are INITIAL_REPLAY_SIZE experiences in the memory batch\n",
    "                #then start replaying\n",
    "                batch = memory.sample(BATCH_SIZE) #Get a BATCH_SIZE experiences for replaying\n",
    "                DQNAgent.replay(batch, BATCH_SIZE)#Do relaying\n",
    "                train = True #Indicate the training starts\n",
    "            total_reward = total_reward + reward #Plus the reward to the total rewad of the episode\n",
    "            s = s_next #Assign the next state for the next step.\n",
    "            \n",
    "            #Saving data to file\n",
    "            '''save_data = np.hstack([episode_i+1,step+1,reward,total_reward,action, DQNAgent.epsilon, terminate]).reshape(1,7)\n",
    "            with open(filename, 'a') as f:\n",
    "                pd.DataFrame(save_data).to_csv(f,encoding='utf-8', index=False, header = False)'''\n",
    "\n",
    "            if terminate == True:\n",
    "                #If the episode ends, then go to the next episode\n",
    "                break\n",
    "            \n",
    "        # Iteration to save the network architecture and weights\n",
    "        if (np.mod(episode_i + 1, SAVE_NETWORK) == 0 and train == True):\n",
    "            DQNAgent.target_train()  # Replace the learning weights for target model with soft replacement\n",
    "            #Save the DQN model\n",
    "            now = datetime.datetime.now() #Get the latest datetime          \n",
    "            DQNAgent.save_model(\"DQNmodel_\" + now.strftime(\"%Y%m%d-%H%M\") + \"_ep\" + str(episode_i+1))   \n",
    "        \n",
    "        #Print the training information after the episode\n",
    "        #print('Episode %d ends. Number of steps is: %d. total_reward = %.2f. Epsilon = %.2f .Termination code: %d' % (episode_i+1, step+1, total_reward, DQNAgent.epsilon, terminate))\n",
    "        #print('A: episode = %d\\ndie_step = %d\\ntotal_reward = %.2f\\nepsilon = %.2f\\nterminate = %d' % (episode_i+1, step+1, total_reward, DQNAgent.epsilon, terminate), end=\"\\n\\n\")\n",
    "        #print('\\nepisode = %d. die_step = %d. reward = %.2f. epsilon = %.2f. terminate = %d' % (episode_i+1, step+1, total_reward, DQNAgent.epsilon, terminate), end=\"\\n\\n\")\n",
    "        print('\\nepisode = {:05d}. step = {:03d}. gold = {:04d}. reward = {:.2f}. epsilon = {:.2f}. reason = {}'.format(episode_i+1, step+1, minerEnv.state.score, total_reward, DQNAgent.epsilon, game_over_reason[minerEnv.state.status]), end=\"\\n\\n\")\n",
    "\n",
    "        #Decreasing the epsilon if the replay starts\n",
    "        if train == True:\n",
    "            DQNAgent.update_epsilon()\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()                \n",
    "        #print(\"Finished.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Miner_Training_Colab_CodeSample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
