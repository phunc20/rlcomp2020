{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "from array import *\n",
    "import os\n",
    "import math\n",
    "from random import randrange\n",
    "import random\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.models import model_from_json\n",
    "#from keras.layers import Dense, Activation\n",
    "#from keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "#from tensorflow.compat.v1.keras import backend as K\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes in GAME_SOCKET_DUMMY.py\n",
    "class ObstacleInfo:\n",
    "    # initial energy for obstacles: Land (key = 0): -1, Forest(key = -1): 0 (random), Trap(key = -2): -10, Swamp (key = -3): -5\n",
    "    types = {0: -1, -1: 0, -2: -10, -3: -5}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.type = 0\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.value = 0\n",
    "        \n",
    "class GoldInfo:\n",
    "    def __init__(self):\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.amount = 0\n",
    "\n",
    "    def loads(self, data):\n",
    "        golds = []\n",
    "        for gd in data:\n",
    "            g = GoldInfo()\n",
    "            g.posx = gd[\"posx\"]\n",
    "            g.posy = gd[\"posy\"]\n",
    "            g.amount = gd[\"amount\"]\n",
    "            golds.append(g)\n",
    "        return golds\n",
    "\n",
    "class PlayerInfo:\n",
    "    STATUS_PLAYING = 0\n",
    "    STATUS_ELIMINATED_WENT_OUT_MAP = 1\n",
    "    STATUS_ELIMINATED_OUT_OF_ENERGY = 2\n",
    "    STATUS_ELIMINATED_INVALID_ACTION = 3\n",
    "    STATUS_STOP_EMPTY_GOLD = 4\n",
    "    STATUS_STOP_END_STEP = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.playerId = id\n",
    "        self.score = 0\n",
    "        self.energy = 0\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.lastAction = -1\n",
    "        self.status = PlayerInfo.STATUS_PLAYING\n",
    "        self.freeCount = 0\n",
    "\n",
    "class GameInfo:\n",
    "    def __init__(self):\n",
    "        self.numberOfPlayers = 1\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.steps = 100\n",
    "        self.golds = []\n",
    "        self.obstacles = []\n",
    "\n",
    "    def loads(self, data):\n",
    "        m = GameInfo()\n",
    "        m.width = data[\"width\"]\n",
    "        m.height = data[\"height\"]\n",
    "        m.golds = GoldInfo().loads(data[\"golds\"])\n",
    "        m.obstacles = data[\"obstacles\"]\n",
    "        m.numberOfPlayers = data[\"numberOfPlayers\"]\n",
    "        m.steps = data[\"steps\"]\n",
    "        return m\n",
    "\n",
    "class UserMatch:\n",
    "    def __init__(self):\n",
    "        self.playerId = 1\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.energy = 50\n",
    "        self.gameinfo = GameInfo()\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "class StepState:\n",
    "    def __init__(self):\n",
    "        self.players = []\n",
    "        self.golds = []\n",
    "        self.changedObstacles = []\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main class in GAME_SOCKET_DUMMY.py\n",
    "class GameSocket:\n",
    "    bog_energy_chain = {-5: -20, -20: -40, -40: -100, -100: -100}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stepCount = 0\n",
    "        self.maxStep = 0\n",
    "        self.mapdir = \"Maps\"  # where to load all pre-defined maps\n",
    "        self.mapid = \"\"\n",
    "        self.userMatch = UserMatch()\n",
    "        self.user = PlayerInfo(1)\n",
    "        self.stepState = StepState()\n",
    "        self.maps = {}  # key: map file name, value: file content\n",
    "        self.map = []  # running map info: 0->Land, -1->Forest, -2->Trap, -3:Swamp, >0:Gold\n",
    "        self.energyOnMap = []  # self.energyOnMap[x][y]: <0, amount of energy which player will consume if it move into (x,y)\n",
    "        self.E = 50\n",
    "        self.resetFlag = True\n",
    "        self.craftUsers = []  # players that craft at current step - for calculating amount of gold\n",
    "        self.bots = []\n",
    "        self.craftMap = {}  # cells that players craft at current step, key: x_y, value: number of players that craft at (x,y)\n",
    "\n",
    "    def init_bots(self):\n",
    "        self.bots = [Bot1(2), Bot2(3), Bot3(4)]  # use bot1(id=2), bot2(id=3), bot3(id=4)\n",
    "        #for (bot) in self.bots:  # at the beginning, all bots will have same position, energy as player\n",
    "        for bot in self.bots:  # at the beginning, all bots will have same position, energy as player\n",
    "            bot.info.posx = self.user.posx\n",
    "            bot.info.posy = self.user.posy\n",
    "            bot.info.energy = self.user.energy\n",
    "            bot.info.lastAction = -1\n",
    "            bot.info.status = PlayerInfo.STATUS_PLAYING\n",
    "            bot.info.score = 0\n",
    "            self.stepState.players.append(bot.info)\n",
    "        self.userMatch.gameinfo.numberOfPlayers = len(self.stepState.players)\n",
    "        #print(\"numberOfPlayers: \", self.userMatch.gameinfo.numberOfPlayers)\n",
    "\n",
    "    def reset(self, requests):  # load new game by given request: [map id (filename), posx, posy, initial energy]\n",
    "        # load new map\n",
    "        self.reset_map(requests[0])\n",
    "        self.userMatch.posx = int(requests[1])\n",
    "        self.userMatch.posy = int(requests[2])\n",
    "        self.userMatch.energy = int(requests[3])\n",
    "        self.userMatch.gameinfo.steps = int(requests[4])\n",
    "        self.maxStep = self.userMatch.gameinfo.steps\n",
    "\n",
    "        # init data for players\n",
    "        self.user.posx = self.userMatch.posx  # in\n",
    "        self.user.posy = self.userMatch.posy\n",
    "        self.user.energy = self.userMatch.energy\n",
    "        self.user.status = PlayerInfo.STATUS_PLAYING\n",
    "        self.user.score = 0\n",
    "        self.stepState.players = [self.user]\n",
    "        self.E = self.userMatch.energy\n",
    "        self.resetFlag = True\n",
    "        self.init_bots()\n",
    "        self.stepCount = 0\n",
    "\n",
    "    def reset_map(self, id):  # load map info\n",
    "        self.mapId = id\n",
    "        self.map = json.loads(self.maps[self.mapId])\n",
    "        self.userMatch = self.map_info(self.map)\n",
    "        self.stepState.golds = self.userMatch.gameinfo.golds\n",
    "        self.map = json.loads(self.maps[self.mapId])\n",
    "        self.energyOnMap = json.loads(self.maps[self.mapId])\n",
    "        for x in range(len(self.map)):\n",
    "            for y in range(len(self.map[x])):\n",
    "                if self.map[x][y] > 0:  # gold\n",
    "                    self.energyOnMap[x][y] = -4\n",
    "                else:  # obstacles\n",
    "                    self.energyOnMap[x][y] = ObstacleInfo.types[self.map[x][y]]\n",
    "\n",
    "    def connect(self): # simulate player's connect request\n",
    "        print(\"Connected to server.\")\n",
    "        for mapid in range(len(Maps)):\n",
    "            filename = \"map\" + str(mapid)\n",
    "            print(\"Found: \" + filename)\n",
    "            self.maps[filename] = str(Maps[mapid])\n",
    "\n",
    "    def map_info(self, map):  # get map info\n",
    "        # print(map)\n",
    "        userMatch = UserMatch()\n",
    "        userMatch.gameinfo.height = len(map)\n",
    "        userMatch.gameinfo.width = len(map[0])\n",
    "        i = 0\n",
    "        while i < len(map):\n",
    "            j = 0\n",
    "            while j < len(map[i]):\n",
    "                if map[i][j] > 0:  # gold\n",
    "                    g = GoldInfo()\n",
    "                    g.posx = j\n",
    "                    g.posy = i\n",
    "                    g.amount = map[i][j]\n",
    "                    userMatch.gameinfo.golds.append(g)\n",
    "                else:  # obstacles\n",
    "                    o = ObstacleInfo()\n",
    "                    o.posx = j\n",
    "                    o.posy = i\n",
    "                    o.type = -map[i][j]\n",
    "                    o.value = ObstacleInfo.types[map[i][j]]\n",
    "                    userMatch.gameinfo.obstacles.append(o)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        return userMatch\n",
    "\n",
    "    def receive(self):  # send data to player (simulate player's receive request)\n",
    "        if self.resetFlag:  # for the first time -> send game info\n",
    "            self.resetFlag = False\n",
    "            data = self.userMatch.to_json()\n",
    "            for (bot) in self.bots:\n",
    "                bot.new_game(data)\n",
    "            # print(data)\n",
    "            return data\n",
    "        else:  # send step state\n",
    "            self.stepCount = self.stepCount + 1\n",
    "            if self.stepCount >= self.maxStep:\n",
    "                for player in self.stepState.players:\n",
    "                    player.status = PlayerInfo.STATUS_STOP_END_STEP\n",
    "            data = self.stepState.to_json()\n",
    "            #for (bot) in self.bots:  # update bots' state\n",
    "            for bot in self.bots:  # update bots' state\n",
    "                bot.new_state(data)\n",
    "            # print(data)\n",
    "            return data\n",
    "\n",
    "    def send(self, message):  # receive message from player (simulate send request from player)\n",
    "        if message.isnumeric():  # player send action\n",
    "            self.resetFlag = False\n",
    "            self.stepState.changedObstacles = []\n",
    "            action = int(message)\n",
    "            # print(\"Action = \", action)\n",
    "            self.user.lastAction = action\n",
    "            self.craftUsers = []\n",
    "            self.step_action(self.user, action)\n",
    "            for bot in self.bots:\n",
    "                if bot.info.status == PlayerInfo.STATUS_PLAYING:\n",
    "                    action = bot.next_action()\n",
    "                    bot.info.lastAction = action\n",
    "                    # print(\"Bot Action: \", action)\n",
    "                    self.step_action(bot.info, action)\n",
    "            self.action_5_craft()\n",
    "            for c in self.stepState.changedObstacles:\n",
    "                self.map[c[\"posy\"]][c[\"posx\"]] = -c[\"type\"]\n",
    "                self.energyOnMap[c[\"posy\"]][c[\"posx\"]] = c[\"value\"]\n",
    "\n",
    "        else:  # reset game\n",
    "            requests = message.split(\",\")\n",
    "            #print(\"Reset game: \", requests[:3], end='')\n",
    "            self.reset(requests)\n",
    "\n",
    "    def step_action(self, user, action):\n",
    "        switcher = {\n",
    "            0: self.action_0_left,\n",
    "            1: self.action_1_right,\n",
    "            2: self.action_2_up,\n",
    "            3: self.action_3_down,\n",
    "            4: self.action_4_free,\n",
    "            5: self.action_5_craft_pre\n",
    "        }\n",
    "        func = switcher.get(action, self.invalidAction)\n",
    "        func(user)\n",
    "\n",
    "    def action_5_craft_pre(self, user):  # collect players who craft at current step\n",
    "        user.freeCount = 0\n",
    "        if self.map[user.posy][user.posx] <= 0:  # craft at the non-gold cell\n",
    "            user.energy -= 10\n",
    "            if user.energy <= 0:\n",
    "                user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "                user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            user.energy -= 5\n",
    "            if user.energy > 0:\n",
    "                self.craftUsers.append(user)\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                if key in self.craftMap:\n",
    "                    count = self.craftMap[key]\n",
    "                    self.craftMap[key] = count + 1\n",
    "                else:\n",
    "                    self.craftMap[key] = 1\n",
    "            else:\n",
    "                user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "                user.lastAction = 6 #eliminated\n",
    "\n",
    "    def action_0_left(self, user):  # user go left\n",
    "        user.freeCount = 0\n",
    "        user.posx = user.posx - 1\n",
    "        if user.posx < 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_1_right(self, user):  # user go right\n",
    "        user.freeCount = 0\n",
    "        user.posx = user.posx + 1\n",
    "        if user.posx >= self.userMatch.gameinfo.width:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_2_up(self, user):  # user go up\n",
    "        user.freeCount = 0\n",
    "        user.posy = user.posy - 1\n",
    "        if user.posy < 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_3_down(self, user):  # user go right\n",
    "        user.freeCount = 0\n",
    "        user.posy = user.posy + 1\n",
    "        if user.posy >= self.userMatch.gameinfo.height:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_4_free(self, user):  # user free\n",
    "        user.freeCount += 1\n",
    "        if user.freeCount == 1:\n",
    "            user.energy += int(self.E / 4)\n",
    "        elif user.freeCount == 2:\n",
    "            user.energy += int(self.E / 3)\n",
    "        elif user.freeCount == 3:\n",
    "            user.energy += int(self.E / 2)\n",
    "        else:\n",
    "            user.energy = self.E\n",
    "        if user.energy > self.E:\n",
    "            user.energy = self.E\n",
    "\n",
    "    def action_5_craft(self):\n",
    "        craftCount = len(self.craftUsers)\n",
    "        # print (\"craftCount\",craftCount)\n",
    "        if (craftCount > 0):\n",
    "            for user in self.craftUsers:\n",
    "                x = user.posx\n",
    "                y = user.posy\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                c = self.craftMap[key]\n",
    "                m = min(math.ceil(self.map[y][x] / c), 50)\n",
    "                user.score += m\n",
    "                # print (\"user\", user.playerId, m)\n",
    "            for user in self.craftUsers:\n",
    "                x = user.posx\n",
    "                y = user.posy\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                if key in self.craftMap:\n",
    "                    c = self.craftMap[key]\n",
    "                    del self.craftMap[key]\n",
    "                    m = min(math.ceil(self.map[y][x] / c), 50)\n",
    "                    self.map[y][x] -= m * c\n",
    "                    if self.map[y][x] < 0:\n",
    "                        self.map[y][x] = 0\n",
    "                        self.energyOnMap[y][x] = ObstacleInfo.types[0]\n",
    "                    for g in self.stepState.golds:\n",
    "                        if g.posx == x and g.posy == y:\n",
    "                            g.amount = self.map[y][x]\n",
    "                            if g.amount == 0:\n",
    "                                self.stepState.golds.remove(g)\n",
    "                                self.add_changed_obstacle(x, y, 0, ObstacleInfo.types[0])\n",
    "                                if len(self.stepState.golds) == 0:\n",
    "                                    for player in self.stepState.players:\n",
    "                                        player.status = PlayerInfo.STATUS_STOP_EMPTY_GOLD\n",
    "                            break;\n",
    "            self.craftMap = {}\n",
    "\n",
    "    def invalidAction(self, user):\n",
    "        user.status = PlayerInfo.STATUS_ELIMINATED_INVALID_ACTION\n",
    "        user.lastAction = 6 #eliminated\n",
    "\n",
    "    def go_to_pos(self, user):  # player move to cell(x,y)\n",
    "        if self.map[user.posy][user.posx] == -1:\n",
    "            user.energy -= randrange(16) + 5\n",
    "        elif self.map[user.posy][user.posx] == 0:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "        elif self.map[user.posy][user.posx] == -2:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "            self.add_changed_obstacle(user.posx, user.posy, 0, ObstacleInfo.types[0])\n",
    "        elif self.map[user.posy][user.posx] == -3:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "            self.add_changed_obstacle(user.posx, user.posy, 3,\n",
    "                                      self.bog_energy_chain[self.energyOnMap[user.posy][user.posx]])\n",
    "        else:\n",
    "            user.energy -= 4\n",
    "        if user.energy <= 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "            user.lastAction = 6 #eliminated\n",
    "\n",
    "    def add_changed_obstacle(self, x, y, t, v):\n",
    "        added = False\n",
    "        for o in self.stepState.changedObstacles:\n",
    "            if o[\"posx\"] == x and o[\"posy\"] == y:\n",
    "                added = True\n",
    "                break\n",
    "        if added == False:\n",
    "            o = {}\n",
    "            o[\"posx\"] = x\n",
    "            o[\"posy\"] = y\n",
    "            o[\"type\"] = t\n",
    "            o[\"value\"] = v\n",
    "            self.stepState.changedObstacles.append(o)\n",
    "\n",
    "    def close(self):\n",
    "        print(\"Close socket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot1\n",
    "class Bot1:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = self.ACTION_GO_UP\n",
    "            if self.info.posy % 2 == 0:\n",
    "                if self.info.posx < self.state.mapInfo.max_x:\n",
    "                    action = self.ACTION_GO_RIGHT\n",
    "            else:\n",
    "                if self.info.posx > 0:\n",
    "                    action = self.ACTION_GO_LEFT\n",
    "                else:\n",
    "                    action = self.ACTION_GO_DOWN\n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot2\n",
    "class Bot2:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = np.random.randint(0, 4)            \n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot3\n",
    "class Bot3:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = self.ACTION_GO_LEFT\n",
    "            if self.info.posx % 2 == 0:\n",
    "                if self.info.posy < self.state.mapInfo.max_y:\n",
    "                    action = self.ACTION_GO_DOWN\n",
    "            else:\n",
    "                if self.info.posy > 0:\n",
    "                    action = self.ACTION_GO_UP\n",
    "                else:\n",
    "                    action = self.ACTION_GO_RIGHT            \n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinerState.py\n",
    "def str_2_json(str):\n",
    "    return json.loads(str, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class MapInfo:\n",
    "    def __init__(self):\n",
    "        self.max_x = 0 #Width of the map\n",
    "        self.max_y = 0 #Height of the map\n",
    "        self.golds = [] #List of the golds in the map\n",
    "        self.obstacles = []\n",
    "        self.numberOfPlayers = 0\n",
    "        self.maxStep = 0 #The maximum number of step is set for this map\n",
    "\n",
    "    def init_map(self, gameInfo):\n",
    "        #Initialize the map at the begining of each episode\n",
    "        self.max_x = gameInfo[\"width\"] - 1\n",
    "        self.max_y = gameInfo[\"height\"] - 1\n",
    "        self.golds = gameInfo[\"golds\"]\n",
    "        self.obstacles = gameInfo[\"obstacles\"]\n",
    "        self.maxStep = gameInfo[\"steps\"]\n",
    "        self.numberOfPlayers = gameInfo[\"numberOfPlayers\"]\n",
    "\n",
    "    def update(self, golds, changedObstacles):\n",
    "        #Update the map after every step\n",
    "        self.golds = golds\n",
    "        for cob in changedObstacles:\n",
    "            newOb = True\n",
    "            for ob in self.obstacles:\n",
    "                if cob[\"posx\"] == ob[\"posx\"] and cob[\"posy\"] == ob[\"posy\"]:\n",
    "                    newOb = False\n",
    "                    #print(\"cell(\", cob[\"posx\"], \",\", cob[\"posy\"], \") change type from: \", ob[\"type\"], \" -> \",\n",
    "                    #      cob[\"type\"], \" / value: \", ob[\"value\"], \" -> \", cob[\"value\"])\n",
    "                    ob[\"type\"] = cob[\"type\"]\n",
    "                    ob[\"value\"] = cob[\"value\"]\n",
    "                    break\n",
    "            if newOb:\n",
    "                self.obstacles.append(cob)\n",
    "                #print(\"new obstacle: \", cob[\"posx\"], \",\", cob[\"posy\"], \", type = \", cob[\"type\"], \", value = \",\n",
    "                #      cob[\"value\"])\n",
    "\n",
    "    def get_min_x(self):\n",
    "        return min([cell[\"posx\"] for cell in self.golds])\n",
    "\n",
    "    def get_max_x(self):\n",
    "        return max([cell[\"posx\"] for cell in self.golds])\n",
    "\n",
    "    def get_min_y(self):\n",
    "        return min([cell[\"posy\"] for cell in self.golds])\n",
    "\n",
    "    def get_max_y(self):\n",
    "        return max([cell[\"posy\"] for cell in self.golds])\n",
    "\n",
    "    def is_row_has_gold(self, y):\n",
    "        return y in [cell[\"posy\"] for cell in self.golds]\n",
    "\n",
    "    def is_column_has_gold(self, x):\n",
    "        return x in [cell[\"posx\"] for cell in self.golds]\n",
    "\n",
    "    def gold_amount(self, x, y): #Get the amount of golds at cell (x,y)\n",
    "        for cell in self.golds:\n",
    "            if x == cell[\"posx\"] and y == cell[\"posy\"]:\n",
    "                return cell[\"amount\"]\n",
    "        return 0 \n",
    "\n",
    "    def get_obstacle(self, x, y):  # Get the kind of the obstacle at cell(x,y)\n",
    "        for cell in self.obstacles:\n",
    "            if x == cell[\"posx\"] and y == cell[\"posy\"]:\n",
    "                return cell[\"type\"]\n",
    "        return -1  # No obstacle at the cell (x,y)\n",
    "\n",
    "\n",
    "class State:\n",
    "    STATUS_PLAYING = 0\n",
    "    STATUS_ELIMINATED_WENT_OUT_MAP = 1\n",
    "    STATUS_ELIMINATED_OUT_OF_ENERGY = 2\n",
    "    STATUS_ELIMINATED_INVALID_ACTION = 3\n",
    "    STATUS_STOP_EMPTY_GOLD = 4\n",
    "    STATUS_STOP_END_STEP = 5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.end = False\n",
    "        self.score = 0\n",
    "        self.lastAction = None\n",
    "        self.id = 0\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.energy = 0\n",
    "        self.mapInfo = MapInfo()\n",
    "        self.players = []\n",
    "        self.stepCount = 0\n",
    "        self.status = State.STATUS_PLAYING\n",
    "\n",
    "    def init_state(self, data): #parse data from server into object\n",
    "        game_info = str_2_json(data)\n",
    "        self.end = False\n",
    "        self.score = 0\n",
    "        self.lastAction = None\n",
    "        self.id = game_info[\"playerId\"]\n",
    "        self.x = game_info[\"posx\"]\n",
    "        self.y = game_info[\"posy\"]\n",
    "        self.energy = game_info[\"energy\"]\n",
    "        self.mapInfo.init_map(game_info[\"gameinfo\"])\n",
    "        self.stepCount = 0\n",
    "        self.status = State.STATUS_PLAYING\n",
    "        self.players = [{\"playerId\": 2, \"posx\": self.x, \"posy\": self.y},\n",
    "                        {\"playerId\": 3, \"posx\": self.x, \"posy\": self.y},\n",
    "                        {\"playerId\": 4, \"posx\": self.x, \"posy\": self.y}]\n",
    "\n",
    "    def update_state(self, data):\n",
    "        new_state = str_2_json(data)\n",
    "        for player in new_state[\"players\"]:\n",
    "            if player[\"playerId\"] == self.id:\n",
    "                self.x = player[\"posx\"]\n",
    "                self.y = player[\"posy\"]\n",
    "                self.energy = player[\"energy\"]\n",
    "                self.score = player[\"score\"]\n",
    "                self.lastAction = player[\"lastAction\"]\n",
    "                self.status = player[\"status\"]\n",
    "\n",
    "        self.mapInfo.update(new_state[\"golds\"], new_state[\"changedObstacles\"])\n",
    "        self.players = new_state[\"players\"]\n",
    "        for i in range(len(self.players), 4, 1):\n",
    "            self.players.append({\"playerId\": i, \"posx\": self.x, \"posy\": self.y})\n",
    "        self.stepCount = self.stepCount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinerEnv.py\n",
    "TreeID = 1\n",
    "TrapID = 2\n",
    "SwampID = 3\n",
    "class MinerEnv:\n",
    "    def __init__(self):\n",
    "        self.socket = GameSocket()\n",
    "        self.state = State()\n",
    "        \n",
    "        self.score_pre = self.state.score#Storing the last score for designing the reward function\n",
    "\n",
    "    def start(self): #connect to server\n",
    "        self.socket.connect()\n",
    "\n",
    "    def end(self): #disconnect server\n",
    "        self.socket.close()\n",
    "\n",
    "    def send_map_info(self, request):#tell server which map to run\n",
    "        self.socket.send(request)\n",
    "\n",
    "    def reset(self): #start new game\n",
    "        try:\n",
    "            message = self.socket.receive() #receive game info from server\n",
    "            self.state.init_state(message) #init state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def step(self, action): #step process\n",
    "        self.socket.send(action) #send action to server\n",
    "        try:\n",
    "            message = self.socket.receive() #receive new state from server\n",
    "            self.state.update_state(message) #update to local state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # Functions are customized by client\n",
    "    def get_state(self):\n",
    "        # Building the map\n",
    "        #view = np.zeros([self.state.mapInfo.max_x + 1, self.state.mapInfo.max_y + 1], dtype=int)\n",
    "        view = np.zeros([self.state.mapInfo.max_y + 1, self.state.mapInfo.max_x + 1], dtype=int)\n",
    "        for x in range(self.state.mapInfo.max_x + 1):\n",
    "            for y in range(self.state.mapInfo.max_y + 1):\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TreeID:  # Tree\n",
    "                    view[y, x] = -TreeID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TrapID:  # Trap\n",
    "                    view[y, x] = -TrapID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == SwampID: # Swamp\n",
    "                    view[y, x] = -SwampID\n",
    "                if self.state.mapInfo.gold_amount(x, y) > 0:\n",
    "                    view[y, x] = self.state.mapInfo.gold_amount(x, y)\n",
    "\n",
    "        DQNState = view.flatten().tolist() #Flattening the map matrix to a vector\n",
    "        \n",
    "        # Add position and energy of agent to the DQNState\n",
    "        DQNState.append(self.state.x)\n",
    "        DQNState.append(self.state.y)\n",
    "        DQNState.append(self.state.energy)\n",
    "        #Add position of bots \n",
    "        for player in self.state.players:\n",
    "            if player[\"playerId\"] != self.state.id:\n",
    "                DQNState.append(player[\"posx\"])\n",
    "                DQNState.append(player[\"posy\"])\n",
    "                \n",
    "        #Convert the DQNState from list to array for training\n",
    "        DQNState = np.array(DQNState)\n",
    "\n",
    "        return DQNState\n",
    "\n",
    "    def get_reward(self):\n",
    "        # Initialize reward\n",
    "        reward = 0\n",
    "        score_action = self.state.score - self.score_pre\n",
    "        self.score_pre = self.state.score\n",
    "        if score_action > 0:\n",
    "            reward += score_action*(100 - self.state.stepCount)\n",
    "            \n",
    "        ##If the DQN agent crashs into obstacels (Tree, Trap, Swamp), then it should be punished by a negative reward\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == TreeID:  # Tree\n",
    "        #    reward -= TreeID\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == TrapID:  # Trap\n",
    "        #    reward -= TrapID\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == SwampID:  # Swamp\n",
    "        #    reward -= SwampID\n",
    "        #    if self.state.lastAction == 4:\n",
    "        #        reward -= 40\n",
    "\n",
    "        # If out of the map, then the DQN agent should be punished by a larger nagative reward.\n",
    "        if self.state.status == State.STATUS_ELIMINATED_WENT_OUT_MAP:\n",
    "            #if self.state.stepCount < 50:\n",
    "            #    reward += -5*(50 - self.state.stepCount)\n",
    "            reward = 0\n",
    "            \n",
    "        if self.state.status == State.STATUS_STOP_END_STEP:\n",
    "            #reward += (self.state.score/total_gold) * 100\n",
    "            pass\n",
    "        #Run out of energy, then the DQN agent should be punished by a larger nagative reward.\n",
    "        if self.state.status == State.STATUS_ELIMINATED_OUT_OF_ENERGY:\n",
    "            if self.state.lastAction != int(constants.available_actions[\"rest\"]):\n",
    "                # Unless it is the last step and dig was more urgent\n",
    "                reward = 0\n",
    "        \n",
    "        ## control comes to here \\implies our agent is not dead yet\n",
    "        if self.state.status == State.STATUS_PLAYING:\n",
    "            if self.state.energy > 40 and self.state.lastAction == int(constants.available_actions[\"rest\"]):\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward += 1\n",
    "        ## print (\"reward\",reward)\n",
    "        return reward\n",
    "\n",
    "    def check_terminate(self):\n",
    "        #Checking the status of the game\n",
    "        #it indicates the game ends or is playing\n",
    "        return self.state.status != State.STATUS_PLAYING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_replay_len = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/phunc20/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "input_shape = [198] # == env.observation_space.shape\n",
    "n_outputs = 6 # == env.action_space.n\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(32, activation=\"elu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(64, activation=\"elu\"),\n",
    "    keras.layers.Dense(n_outputs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon=0, n_actions=6):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.randint(n_actions)\n",
    "    else:\n",
    "        Q_values = model.predict(state[np.newaxis])\n",
    "        return np.argmax(Q_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3,4))[np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((3,4))[:, np.newaxis, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "replay_memory = deque(maxlen=max_replay_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class deque in module collections:\n",
      "\n",
      "class deque(builtins.object)\n",
      " |  deque([iterable[, maxlen]]) --> deque object\n",
      " |  \n",
      " |  A list-like sequence optimized for data accesses near its endpoints.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      self != 0\n",
      " |  \n",
      " |  __contains__(self, key, /)\n",
      " |      Return key in self.\n",
      " |  \n",
      " |  __copy__(...)\n",
      " |      Return a shallow copy of a deque.\n",
      " |  \n",
      " |  __delitem__(self, key, /)\n",
      " |      Delete self[key].\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __getitem__(self, key, /)\n",
      " |      Return self[key].\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __iadd__(self, value, /)\n",
      " |      Implement self+=value.\n",
      " |  \n",
      " |  __imul__(self, value, /)\n",
      " |      Implement self*=value.\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self, /)\n",
      " |      Implement iter(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __len__(self, /)\n",
      " |      Return len(self).\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      Return state information for pickling.\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __reversed__(...)\n",
      " |      D.__reversed__() -- return a reverse iterator over the deque\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __setitem__(self, key, value, /)\n",
      " |      Set self[key] to value.\n",
      " |  \n",
      " |  __sizeof__(...)\n",
      " |      D.__sizeof__() -- size of D in memory, in bytes\n",
      " |  \n",
      " |  append(...)\n",
      " |      Add an element to the right side of the deque.\n",
      " |  \n",
      " |  appendleft(...)\n",
      " |      Add an element to the left side of the deque.\n",
      " |  \n",
      " |  clear(...)\n",
      " |      Remove all elements from the deque.\n",
      " |  \n",
      " |  copy(...)\n",
      " |      Return a shallow copy of a deque.\n",
      " |  \n",
      " |  count(...)\n",
      " |      D.count(value) -> integer -- return number of occurrences of value\n",
      " |  \n",
      " |  extend(...)\n",
      " |      Extend the right side of the deque with elements from the iterable\n",
      " |  \n",
      " |  extendleft(...)\n",
      " |      Extend the left side of the deque with elements from the iterable\n",
      " |  \n",
      " |  index(...)\n",
      " |      D.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      " |      Raises ValueError if the value is not present.\n",
      " |  \n",
      " |  insert(...)\n",
      " |      D.insert(index, object) -- insert object before index\n",
      " |  \n",
      " |  pop(...)\n",
      " |      Remove and return the rightmost element.\n",
      " |  \n",
      " |  popleft(...)\n",
      " |      Remove and return the leftmost element.\n",
      " |  \n",
      " |  remove(...)\n",
      " |      D.remove(value) -- remove first occurrence of value.\n",
      " |  \n",
      " |  reverse(...)\n",
      " |      D.reverse() -- reverse *IN PLACE*\n",
      " |  \n",
      " |  rotate(...)\n",
      " |      Rotate the deque n steps to the right (default n=1).  If n is negative, rotates left.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  maxlen\n",
      " |      maximum size of a deque or None if unbounded\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(deque)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_experiences(batch_size):\n",
    "    indices = np.random.randint(len(replay_memory), size=batch_size)\n",
    "    batch = [replay_memory[index] for index in indices]\n",
    "    states, actions, rewards, next_states, dones = [\n",
    "        np.array([experience[field_index] for experience in batch])\n",
    "        for field_index in range(5)]\n",
    "    return states, actions, rewards, next_states, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one_step(env, state, epsilon):\n",
    "    action = epsilon_greedy_policy(state, epsilon)\n",
    "    #next_state, reward, done, info = env.step(action)\n",
    "    env.step(str(action))\n",
    "    next_state = env.get_state()\n",
    "    reward = env.get_reward()\n",
    "    done = env.check_terminate()\n",
    "    replay_memory.append((state, action, reward, next_state, done))\n",
    "    #gc.collect\n",
    "    return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "discount_rate = 0.95\n",
    "optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "def training_step(batch_size):\n",
    "    experiences = sample_experiences(batch_size)\n",
    "    states, actions, rewards, next_states, dones = experiences\n",
    "    next_Q_values = model.predict(next_states)\n",
    "    max_next_Q_values = np.max(next_Q_values, axis=1)\n",
    "    target_Q_values = rewards + (1 - dones) * discount_rate * max_next_Q_values\n",
    "    mask = tf.one_hot(actions, n_outputs)\n",
    "    with tf.GradientTape() as tape:\n",
    "        all_Q_values = model(states)\n",
    "        Q_values = tf.reduce_sum(all_Q_values * mask, axis=1, keepdims=True)\n",
    "        loss = tf.reduce_mean(loss_fn(target_Q_values, Q_values))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.seed(42)\n",
    "np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "scores = [] \n",
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Maps\n",
    "#This function is used to create 05 maps instead of loading them from Maps folder in the local\n",
    "def CreateMaps():\n",
    "    map0 = [\n",
    "      [0,  0,  -2,  100,  0,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  0,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  0,  0,  0,  -1,  -1,  -1,  0, 0,  100,  0,  0,  0,  0,  50,  -2,  0,0],\n",
    "      [0,  0,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  50, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  200,  -2,  -2,  300,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  0,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  -1,  -1,  0,  0,  -1,  -1,  0,  0,  700,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 0,100],\n",
    "      [0,  0, 0, 500,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  0,  400,  -2,  -1,  -1,  500,  0,  -2,  0,  -3,  100,  0, 0,0]\n",
    "    ]\n",
    "    map1 = [\n",
    "      [0,  0,  -2,  0,  0,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  100, 0,  0,  -3,  -1,  0,  -2,  100,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  0,  0,  0,  -1,  -1,  -1,  0, 0,  0,  0,  0,  0,  50,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  50, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  300,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [500,  -1,  -1,  0,  0,  -1,  -1,  0,  700,  0,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 0,0],\n",
    "      [0,  0, 0, 0,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  100,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "    ]\n",
    "    map2 = [\n",
    "      [0,  0,  -2,  0,  0,  0,  -1,  -1,  -3,  0,  100,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  0,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0 ],\n",
    "      [0,  0,  -1,  0,  0,  0,  100,  -1,  -1,  -1,  0, 0,  50,  0,  0,  0,  50,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  0, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0, 300,  0,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  -1,  -1,  0,  0,  -1,  -1,  700,  0,  0,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 0,0],\n",
    "      [0,  0, 0, 0,  0,  500,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  700,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "    ]\n",
    "    map3 = [\n",
    "      [0,  0,  -2,  0,  0,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  0,  0,  100,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  100,  0,  0,  -1,  -1,  -1,  0, 0,  0,  0,  50,  0,  50,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  0, -2,  0,  0,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  0,  0,  300,  -3,  0,  700,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  -1,  -1,  0,  0,  -1,  -1,  0,  0,  0,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 100,0],\n",
    "      [500,  0, 0, 0,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "\n",
    "    ]\n",
    "    map4 = [\n",
    "      [0,  0,  -2,  0,  100,  0,  -1,  -1,  -3,  0,  0,  0,  -1,  -1,  0,  0,  -3,  0,  -1,  -1,0],\n",
    "      [-1,-1,  -2,  0, 0,  0,  -3,  -1,  0,  -2,  100,  0,  0,  -1,  0,  -1,  0,  -2,  -1,  0,0],\n",
    "      [0,  0,  -1,  0,  0,  0,  0,  -1,  -1,  -1,  0, 0,  0,  0,  50,  0,  0,  0,  -2,  0,0],\n",
    "      [0,  200,  0,  0,  -2,  0,  0,  0,  0,  0,  0,  0,  -1,  0, -2,  0,  50,  -1,  -1,  0,0],\n",
    "      [-2, 0,  0,  -2,  -2,  0,  0, 0,  -2,  -2,  0,  0,  -3,  0,  -1,  0,  0,  -3,  -1,  0,0],\n",
    "      [0,  -1,  0,  0,  300,  0,  0,  -3,  0,  0,  -1,  -1,  0,  0,  0,  0,  0,  0,  -2,  0,0],\n",
    "      [500,  -1,  -1,  0,  0,  -1,  -1,  0,  0,  700,  -1,  0,  0,  0,  -2,  -1,  -1,  0,  0, 100,0],\n",
    "      [0,  0, 0, 0,  0,  0,  -1,  0,  -2,  -2,  -1,  -1,  0,  0,  -2,  0,  -3,  0,  0,  -1,0],\n",
    "      [-1,  -1, 0,-2 ,  0,  -1,  -2,  400,  0,  -2,  -1,  -1,  0,  500,  -2,  0,  -3,  0,  0, 100,0]\n",
    "    ]\n",
    "    Maps = (map0,map1,map2,map3,map4)\n",
    "    return Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_over_reason = (\n",
    "    \"playing\",\n",
    "    \"went_out_map\",\n",
    "    \"out_of_energy\",\n",
    "    \"invalid_action\",\n",
    "    \"no_more_gold\",\n",
    "    \"no_more_step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to server.\n",
      "Found: map0\n",
      "Found: map1\n",
      "Found: map2\n",
      "Found: map3\n",
      "Found: map4\n"
     ]
    }
   ],
   "source": [
    "Maps = CreateMaps()\n",
    "env = MinerEnv() # Creating a communication environment between the DQN model and the game environment\n",
    "env.start() # Connect to the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Episode     0)   Gold:    0   sum_reward:     5   Steps:    6   eps: 1.000   (out_of_energy)\n",
      "(Episode     1)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.995   (out_of_energy)\n",
      "(Episode     2)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.990   (out_of_energy)\n",
      "(Episode     3)   Gold:    0   sum_reward:    17   Steps:   18   eps: 0.986   (out_of_energy)\n",
      "(Episode     4)   Gold:   50   sum_reward:  3580   Steps:   31   eps: 0.981   (out_of_energy)\n",
      "(Episode     5)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.976   (out_of_energy)\n",
      "(Episode     6)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.971   (out_of_energy)\n",
      "(Episode     7)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.967   (out_of_energy)\n",
      "(Episode     8)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.962   (went_out_map)\n",
      "(Episode     9)   Gold:    0   sum_reward:    21   Steps:   22   eps: 0.957   (out_of_energy)\n",
      "(Episode    10)   Gold:    0   sum_reward:     8   Steps:    9   eps: 0.952   (out_of_energy)\n",
      "(Episode    11)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.948   (out_of_energy)\n",
      "(Episode    12)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.943   (went_out_map)\n",
      "(Episode    13)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.938   (out_of_energy)\n",
      "(Episode    14)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.933   (went_out_map)\n",
      "(Episode    15)   Gold:    0   sum_reward:    22   Steps:   23   eps: 0.929   (out_of_energy)\n",
      "(Episode    16)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.924   (out_of_energy)\n",
      "(Episode    17)   Gold:    0   sum_reward:    24   Steps:   25   eps: 0.919   (went_out_map)\n",
      "(Episode    18)   Gold:   50   sum_reward:  3297   Steps:   48   eps: 0.914   (out_of_energy)\n",
      "(Episode    19)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.910   (went_out_map)\n",
      "(Episode    20)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.905   (went_out_map)\n",
      "(Episode    21)   Gold:    0   sum_reward:    22   Steps:   23   eps: 0.900   (out_of_energy)\n",
      "(Episode    22)   Gold:    0   sum_reward:    16   Steps:   17   eps: 0.895   (out_of_energy)\n",
      "(Episode    23)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.890   (out_of_energy)\n",
      "(Episode    24)   Gold:    0   sum_reward:    11   Steps:   12   eps: 0.886   (out_of_energy)\n",
      "(Episode    25)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.881   (went_out_map)\n",
      "(Episode    26)   Gold:    0   sum_reward:    11   Steps:   12   eps: 0.876   (out_of_energy)\n",
      "(Episode    27)   Gold:    0   sum_reward:    48   Steps:   49   eps: 0.871   (out_of_energy)\n",
      "(Episode    28)   Gold:    0   sum_reward:    25   Steps:   26   eps: 0.867   (out_of_energy)\n",
      "(Episode    29)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.862   (out_of_energy)\n",
      "(Episode    30)   Gold:    0   sum_reward:    13   Steps:   14   eps: 0.857   (went_out_map)\n",
      "(Episode    31)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.852   (out_of_energy)\n",
      "(Episode    32)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.848   (went_out_map)\n",
      "(Episode    33)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.843   (went_out_map)\n",
      "(Episode    34)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.838   (went_out_map)\n",
      "(Episode    35)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.833   (went_out_map)\n",
      "(Episode    36)   Gold:    0   sum_reward:    21   Steps:   22   eps: 0.829   (out_of_energy)\n",
      "(Episode    37)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.824   (out_of_energy)\n",
      "(Episode    38)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.819   (went_out_map)\n",
      "(Episode    39)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.814   (went_out_map)\n",
      "(Episode    40)   Gold:    0   sum_reward:    32   Steps:   33   eps: 0.810   (went_out_map)\n",
      "(Episode    41)   Gold:    0   sum_reward:    19   Steps:   20   eps: 0.805   (went_out_map)\n",
      "(Episode    42)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.800   (out_of_energy)\n",
      "(Episode    43)   Gold:    0   sum_reward:    25   Steps:   26   eps: 0.795   (out_of_energy)\n",
      "(Episode    44)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.790   (out_of_energy)\n",
      "(Episode    45)   Gold:    0   sum_reward:     2   Steps:    3   eps: 0.786   (went_out_map)\n",
      "(Episode    46)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.781   (out_of_energy)\n",
      "(Episode    47)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.776   (out_of_energy)\n",
      "(Episode    48)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.771   (out_of_energy)\n",
      "(Episode    49)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.767   (went_out_map)\n",
      "(Episode    50)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.762   (out_of_energy)\n",
      "(Episode    51)   Gold:    0   sum_reward:    20   Steps:   21   eps: 0.757   (went_out_map)\n",
      "(Episode    52)   Gold:    0   sum_reward:     2   Steps:    3   eps: 0.752   (went_out_map)\n",
      "(Episode    53)   Gold:    0   sum_reward:    23   Steps:   24   eps: 0.748   (out_of_energy)\n",
      "(Episode    54)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.743   (out_of_energy)\n",
      "(Episode    55)   Gold:    0   sum_reward:    11   Steps:   12   eps: 0.738   (out_of_energy)\n",
      "(Episode    56)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.733   (out_of_energy)\n",
      "(Episode    57)   Gold:    0   sum_reward:     8   Steps:    9   eps: 0.729   (went_out_map)\n",
      "(Episode    58)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.724   (went_out_map)\n",
      "(Episode    59)   Gold:    0   sum_reward:    26   Steps:   27   eps: 0.719   (out_of_energy)\n",
      "(Episode    60)   Gold:    0   sum_reward:    13   Steps:   14   eps: 0.714   (out_of_energy)\n",
      "(Episode    61)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.710   (out_of_energy)\n",
      "(Episode    62)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.705   (out_of_energy)\n",
      "(Episode    63)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.700   (out_of_energy)\n",
      "(Episode    64)   Gold:    0   sum_reward:    13   Steps:   14   eps: 0.695   (out_of_energy)\n",
      "(Episode    65)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.690   (went_out_map)\n",
      "(Episode    66)   Gold:   50   sum_reward:  4610   Steps:   11   eps: 0.686   (out_of_energy)\n",
      "(Episode    67)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.681   (went_out_map)\n",
      "(Episode    68)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.676   (went_out_map)\n",
      "(Episode    69)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.671   (went_out_map)\n",
      "(Episode    70)   Gold:    0   sum_reward:    21   Steps:   22   eps: 0.667   (out_of_energy)\n",
      "(Episode    71)   Gold:   50   sum_reward:  4952   Steps:    3   eps: 0.662   (went_out_map)\n",
      "(Episode    72)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.657   (out_of_energy)\n",
      "(Episode    73)   Gold:    0   sum_reward:     8   Steps:    9   eps: 0.652   (out_of_energy)\n",
      "(Episode    74)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.648   (out_of_energy)\n",
      "(Episode    75)   Gold:    0   sum_reward:    20   Steps:   21   eps: 0.643   (went_out_map)\n",
      "(Episode    76)   Gold:    0   sum_reward:    35   Steps:   36   eps: 0.638   (went_out_map)\n",
      "(Episode    77)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.633   (went_out_map)\n",
      "(Episode    78)   Gold:    0   sum_reward:    25   Steps:   26   eps: 0.629   (went_out_map)\n",
      "(Episode    79)   Gold:    0   sum_reward:    19   Steps:   20   eps: 0.624   (out_of_energy)\n",
      "(Episode    80)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.619   (out_of_energy)\n",
      "(Episode    81)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.614   (went_out_map)\n",
      "(Episode    82)   Gold:   50   sum_reward:  4465   Steps:   16   eps: 0.610   (out_of_energy)\n",
      "(Episode    83)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.605   (out_of_energy)\n",
      "(Episode    84)   Gold:    0   sum_reward:    26   Steps:   27   eps: 0.600   (went_out_map)\n",
      "(Episode    85)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.595   (went_out_map)\n",
      "(Episode    86)   Gold:    0   sum_reward:    18   Steps:   19   eps: 0.590   (out_of_energy)\n",
      "(Episode    87)   Gold:    0   sum_reward:    18   Steps:   19   eps: 0.586   (out_of_energy)\n",
      "(Episode    88)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.581   (went_out_map)\n",
      "(Episode    89)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.576   (went_out_map)\n",
      "(Episode    90)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.571   (out_of_energy)\n",
      "(Episode    91)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.567   (went_out_map)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Episode    92)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.562   (out_of_energy)\n",
      "(Episode    93)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.557   (out_of_energy)\n",
      "(Episode    94)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.552   (out_of_energy)\n",
      "(Episode    95)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.548   (went_out_map)\n",
      "(Episode    96)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.543   (went_out_map)\n",
      "(Episode    97)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.538   (out_of_energy)\n",
      "(Episode    98)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.533   (went_out_map)\n",
      "(Episode    99)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.529   (out_of_energy)\n",
      "(Episode   100)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.524   (went_out_map)\n",
      "(Episode   101)   Gold:    0   sum_reward:    24   Steps:   25   eps: 0.519   (out_of_energy)\n",
      "(Episode   102)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.514   (out_of_energy)\n",
      "(Episode   103)   Gold:    0   sum_reward:    15   Steps:   16   eps: 0.510   (out_of_energy)\n",
      "(Episode   104)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.505   (out_of_energy)\n",
      "(Episode   105)   Gold:  100   sum_reward:  9657   Steps:    8   eps: 0.500   (went_out_map)\n",
      "(Episode   106)   Gold:    0   sum_reward:    15   Steps:   16   eps: 0.495   (out_of_energy)\n",
      "(Episode   107)   Gold:    0   sum_reward:     8   Steps:    9   eps: 0.490   (went_out_map)\n",
      "(Episode   108)   Gold:    0   sum_reward:    17   Steps:   18   eps: 0.486   (out_of_energy)\n",
      "(Episode   109)   Gold:    0   sum_reward:    11   Steps:   12   eps: 0.481   (out_of_energy)\n",
      "(Episode   110)   Gold:    0   sum_reward:    20   Steps:   21   eps: 0.476   (out_of_energy)\n",
      "(Episode   111)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.471   (went_out_map)\n",
      "(Episode   112)   Gold:    0   sum_reward:    17   Steps:   18   eps: 0.467   (out_of_energy)\n",
      "(Episode   113)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.462   (out_of_energy)\n",
      "(Episode   114)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.457   (out_of_energy)\n",
      "(Episode   115)   Gold:    0   sum_reward:    20   Steps:   21   eps: 0.452   (out_of_energy)\n",
      "(Episode   116)   Gold:    0   sum_reward:    15   Steps:   16   eps: 0.448   (went_out_map)\n",
      "(Episode   117)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.443   (went_out_map)\n",
      "(Episode   118)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.438   (went_out_map)\n",
      "(Episode   119)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.433   (went_out_map)\n",
      "(Episode   120)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.429   (out_of_energy)\n",
      "(Episode   121)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.424   (out_of_energy)\n",
      "(Episode   122)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.419   (went_out_map)\n",
      "(Episode   123)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.414   (went_out_map)\n",
      "(Episode   124)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.410   (out_of_energy)\n",
      "(Episode   125)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.405   (out_of_energy)\n",
      "(Episode   126)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.400   (out_of_energy)\n",
      "(Episode   127)   Gold:    0   sum_reward:     5   Steps:    6   eps: 0.395   (went_out_map)\n",
      "(Episode   128)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.390   (went_out_map)\n",
      "(Episode   129)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.386   (out_of_energy)\n",
      "(Episode   130)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.381   (out_of_energy)\n",
      "(Episode   131)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.376   (out_of_energy)\n",
      "(Episode   132)   Gold:   50   sum_reward:  4903   Steps:    4   eps: 0.371   (went_out_map)\n",
      "(Episode   133)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.367   (out_of_energy)\n",
      "(Episode   134)   Gold:    0   sum_reward:     3   Steps:    4   eps: 0.362   (out_of_energy)\n",
      "(Episode   135)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.357   (went_out_map)\n",
      "(Episode   136)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.352   (out_of_energy)\n",
      "(Episode   137)   Gold:    0   sum_reward:    14   Steps:   15   eps: 0.348   (went_out_map)\n",
      "(Episode   138)   Gold:    0   sum_reward:    12   Steps:   13   eps: 0.343   (out_of_energy)\n",
      "(Episode   139)   Gold:    0   sum_reward:    14   Steps:   15   eps: 0.338   (went_out_map)\n",
      "(Episode   140)   Gold:    0   sum_reward:    20   Steps:   21   eps: 0.333   (out_of_energy)\n",
      "(Episode   141)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.329   (out_of_energy)\n",
      "(Episode   142)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.324   (went_out_map)\n",
      "(Episode   143)   Gold:    0   sum_reward:     2   Steps:    3   eps: 0.319   (went_out_map)\n",
      "(Episode   144)   Gold:    0   sum_reward:     4   Steps:    5   eps: 0.314   (out_of_energy)\n",
      "(Episode   145)   Gold:    0   sum_reward:    13   Steps:   14   eps: 0.310   (out_of_energy)\n",
      "(Episode   146)   Gold:    0   sum_reward:     9   Steps:   10   eps: 0.305   (went_out_map)\n",
      "(Episode   147)   Gold:    0   sum_reward:     1   Steps:    2   eps: 0.300   (went_out_map)\n",
      "(Episode   148)   Gold:    0   sum_reward:    15   Steps:   16   eps: 0.295   (out_of_energy)\n",
      "(Episode   149)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.290   (out_of_energy)\n",
      "(Episode   150)   Gold:    0   sum_reward:     6   Steps:    7   eps: 0.286   (went_out_map)\n",
      "(Episode   151)   Gold:   50   sum_reward:  4908   Steps:    9   eps: 0.281   (out_of_energy)\n",
      "(Episode   152)   Gold:    0   sum_reward:    10   Steps:   11   eps: 0.276   (out_of_energy)\n",
      "(Episode   153)   Gold:    0   sum_reward:     0   Steps:    1   eps: 0.271   (went_out_map)\n",
      "(Episode   154)   Gold:    0   sum_reward:     7   Steps:    8   eps: 0.267   (out_of_energy)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-615153800409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#model.set_weights(best_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-fb00b5496314>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmax_next_Q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_Q_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtarget_Q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdiscount_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_next_Q_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mall_Q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   3017\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moff_exists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m       \u001b[0;31m# off_value not provided: assign to value 0 of type dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0moff_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"off_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0moff_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_episodes = 300\n",
    "n_epsilon_decay = int(n_episodes*.7)\n",
    "n_max_steps = 100\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    mapID = np.random.randint(0, 5)\n",
    "    posID_x = np.random.randint(constants.width) \n",
    "    posID_y = np.random.randint(constants.height)\n",
    "    request = \"map{},{},{},50,100\".format(mapID, posID_x, posID_y)\n",
    "    env.send_map_info(request)\n",
    "    #obs = env.reset()\n",
    "    env.reset()\n",
    "    obs = env.get_state()\n",
    "    sum_reward = 0\n",
    "    for step in range(n_max_steps):\n",
    "        epsilon = max(1 - episode / n_epsilon_decay, 0.01)\n",
    "        obs, reward, done = play_one_step(env, obs, epsilon)\n",
    "        sum_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    score = env.state.score*(n_max_steps - step)\n",
    "    #scores.append(score)\n",
    "    if score > best_score:\n",
    "        best_weights = model.get_weights()\n",
    "        best_score = reward\n",
    "    #print(\"\\rEpisode: {}, Steps: {}, eps: {:.3f}\".format(episode, step + 1, epsilon), end=\"\")\n",
    "    #print(\"Episode: {: 5d}, Gold: {: 4d}, Steps: {: 3d}, eps: {:.3f}. ({})\".format(episode, env.state.score, step + 1, epsilon, game_over_reason[env.state.status]), end=\"\\n\\n\")\n",
    "    #print(\"(Episode: {: 5d})   Gold: {: 4d}, Steps: {: 3d}, eps: {:.3f}. ({})\".format(episode, env.state.score, step + 1, epsilon, game_over_reason[env.state.status]))\n",
    "    print(\"(Episode {: 5d})   Gold: {: 4d}   sum_reward: {: 5d}   Steps: {: 4d}   eps: {:.3f}   ({})\".format(episode, env.state.score, sum_reward, step + 1, epsilon, game_over_reason[env.state.status]))\n",
    "\n",
    "    if episode > 100:\n",
    "        training_step(batch_size)\n",
    "\n",
    "#model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(replay_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(typecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(posID_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(replay_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(ArrayType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(Bot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(UserMatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(\"sys.getsizeof({})\".format(dir()[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sys.getsizeof(_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sys.getsizeof(Activation) + \\\n",
    "sys.getsizeof(ArrayType) + \\\n",
    "sys.getsizeof(Bot1) + \\\n",
    "sys.getsizeof(Bot2) + \\\n",
    "sys.getsizeof(Bot3) + \\\n",
    "sys.getsizeof(CreateMaps) + \\\n",
    "sys.getsizeof(Dense) + \\\n",
    "sys.getsizeof(GameInfo) + \\\n",
    "sys.getsizeof(GameSocket) + \\\n",
    "sys.getsizeof(GoldInfo) + \\\n",
    "sys.getsizeof(K) + \\\n",
    "sys.getsizeof(MapInfo) + \\\n",
    "sys.getsizeof(Maps) + \\\n",
    "sys.getsizeof(MinerEnv) + \\\n",
    "sys.getsizeof(ObstacleInfo) + \\\n",
    "sys.getsizeof(PlayerInfo) + \\\n",
    "sys.getsizeof(Sequential) + \\\n",
    "sys.getsizeof(State) + \\\n",
    "sys.getsizeof(StepState) + \\\n",
    "sys.getsizeof(SwampID) + \\\n",
    "sys.getsizeof(TrapID) + \\\n",
    "sys.getsizeof(TreeID) + \\\n",
    "sys.getsizeof(UserMatch) + \\\n",
    "sys.getsizeof(array) + \\\n",
    "sys.getsizeof(batch_size) + \\\n",
    "sys.getsizeof(best_score) + \\\n",
    "sys.getsizeof(best_weights) + \\\n",
    "sys.getsizeof(constants) + \\\n",
    "sys.getsizeof(datetime) + \\\n",
    "sys.getsizeof(deque) + \\\n",
    "sys.getsizeof(discount_rate) + \\\n",
    "sys.getsizeof(done) + \\\n",
    "sys.getsizeof(env) + \\\n",
    "sys.getsizeof(episode) + \\\n",
    "sys.getsizeof(epsilon) + \\\n",
    "sys.getsizeof(epsilon_greedy_policy) + \\\n",
    "sys.getsizeof(game_over_reason) + \\\n",
    "sys.getsizeof(input_shape) + \\\n",
    "sys.getsizeof(json) + \\\n",
    "sys.getsizeof(keras) + \\\n",
    "sys.getsizeof(loss_fn) + \\\n",
    "sys.getsizeof(mapID) + \\\n",
    "sys.getsizeof(math) + \\\n",
    "sys.getsizeof(max_replay_len) + \\\n",
    "sys.getsizeof(model) + \\\n",
    "sys.getsizeof(model_from_json) + \\\n",
    "sys.getsizeof(n_episodes) + \\\n",
    "sys.getsizeof(n_epsilon_decay) + \\\n",
    "sys.getsizeof(n_max_steps) + \\\n",
    "sys.getsizeof(n_outputs) + \\\n",
    "sys.getsizeof(np) + \\\n",
    "sys.getsizeof(obs) + \\\n",
    "sys.getsizeof(optimizer) + \\\n",
    "sys.getsizeof(optimizers) + \\\n",
    "sys.getsizeof(os) + \\\n",
    "sys.getsizeof(play_one_step) + \\\n",
    "sys.getsizeof(posID_x) + \\\n",
    "sys.getsizeof(posID_y) + \\\n",
    "sys.getsizeof(random) + \\\n",
    "sys.getsizeof(randrange) + \\\n",
    "sys.getsizeof(replay_memory) + \\\n",
    "sys.getsizeof(request) + \\\n",
    "sys.getsizeof(reward) + \\\n",
    "sys.getsizeof(sample_experiences) + \\\n",
    "sys.getsizeof(score) + \\\n",
    "sys.getsizeof(scores) + \\\n",
    "sys.getsizeof(step) + \\\n",
    "sys.getsizeof(str_2_json) + \\\n",
    "sys.getsizeof(sum_reward) + \\\n",
    "sys.getsizeof(sys) + \\\n",
    "sys.getsizeof(tf) + \\\n",
    "sys.getsizeof(training_step) + \\\n",
    "sys.getsizeof(typecodes) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sys.getsizeof(Activation) +\\\n",
    "sys.getsizeof(ArrayType) +\\\n",
    "sys.getsizeof(Bot1) +\\\n",
    "sys.getsizeof(Bot2) +\\\n",
    "sys.getsizeof(Bot3) +\\\n",
    "sys.getsizeof(CreateMaps) +\\\n",
    "sys.getsizeof(Dense) +\\\n",
    "sys.getsizeof(GameInfo) +\\\n",
    "sys.getsizeof(GameSocket) +\\\n",
    "sys.getsizeof(GoldInfo) +\\\n",
    "sys.getsizeof(In) +\\\n",
    "sys.getsizeof(K) +\\\n",
    "sys.getsizeof(MapInfo) +\\\n",
    "sys.getsizeof(Maps) +\\\n",
    "sys.getsizeof(MinerEnv) +\\\n",
    "sys.getsizeof(ObstacleInfo) +\\\n",
    "sys.getsizeof(Out) +\\\n",
    "sys.getsizeof(PlayerInfo) +\\\n",
    "sys.getsizeof(Sequential) +\\\n",
    "sys.getsizeof(State) +\\\n",
    "sys.getsizeof(StepState) +\\\n",
    "sys.getsizeof(SwampID) +\\\n",
    "sys.getsizeof(TrapID) +\\\n",
    "sys.getsizeof(TreeID) +\\\n",
    "sys.getsizeof(UserMatch) +\\\n",
    "sys.getsizeof(_) +\\\n",
    "sys.getsizeof(_12) +\\\n",
    "sys.getsizeof(_13) +\\\n",
    "sys.getsizeof(_27) +\\\n",
    "sys.getsizeof(_28) +\\\n",
    "sys.getsizeof(_29) +\\\n",
    "sys.getsizeof(_30) +\\\n",
    "sys.getsizeof(_31) +\\\n",
    "sys.getsizeof(_32) +\\\n",
    "sys.getsizeof(_33) +\\\n",
    "sys.getsizeof(_34) +\\\n",
    "sys.getsizeof(_35) +\\\n",
    "sys.getsizeof(_39) +\\\n",
    "sys.getsizeof(_41) +\\\n",
    "sys.getsizeof(_42) +\\\n",
    "sys.getsizeof(_43) +\\\n",
    "sys.getsizeof(_44) +\\\n",
    "sys.getsizeof(_45) +\\\n",
    "sys.getsizeof(_46) +\\\n",
    "sys.getsizeof(_47) +\\\n",
    "sys.getsizeof(_48) +\\\n",
    "sys.getsizeof(_52) +\\\n",
    "sys.getsizeof(_53) +\\\n",
    "sys.getsizeof(_54) +\\\n",
    "sys.getsizeof(_55) +\\\n",
    "sys.getsizeof(_56) +\\\n",
    "sys.getsizeof(_57) +\\\n",
    "sys.getsizeof(_58) +\\\n",
    "sys.getsizeof(_59) +\\\n",
    "sys.getsizeof(_60) +\\\n",
    "sys.getsizeof(_61) +\\\n",
    "sys.getsizeof(_62) +\\\n",
    "sys.getsizeof(_63) +\\\n",
    "sys.getsizeof(_64) +\\\n",
    "sys.getsizeof(_65) +\\\n",
    "sys.getsizeof(__) +\\\n",
    "sys.getsizeof(___) +\\\n",
    "sys.getsizeof(__builtin__) +\\\n",
    "sys.getsizeof(__builtins__) +\\\n",
    "sys.getsizeof(__doc__) +\\\n",
    "sys.getsizeof(__loader__) +\\\n",
    "sys.getsizeof(__name__) +\\\n",
    "sys.getsizeof(__package__) +\\\n",
    "sys.getsizeof(__spec__) +\\\n",
    "sys.getsizeof(_dh) +\\\n",
    "sys.getsizeof(_i) +\\\n",
    "sys.getsizeof(_i1) +\\\n",
    "sys.getsizeof(_i10) +\\\n",
    "sys.getsizeof(_i11) +\\\n",
    "sys.getsizeof(_i12) +\\\n",
    "sys.getsizeof(_i13) +\\\n",
    "sys.getsizeof(_i14) +\\\n",
    "sys.getsizeof(_i15) +\\\n",
    "sys.getsizeof(_i16) +\\\n",
    "sys.getsizeof(_i17) +\\\n",
    "sys.getsizeof(_i18) +\\\n",
    "sys.getsizeof(_i19) +\\\n",
    "sys.getsizeof(_i2) +\\\n",
    "sys.getsizeof(_i20) +\\\n",
    "sys.getsizeof(_i21) +\\\n",
    "sys.getsizeof(_i22) +\\\n",
    "sys.getsizeof(_i23) +\\\n",
    "sys.getsizeof(_i24) +\\\n",
    "sys.getsizeof(_i25) +\\\n",
    "sys.getsizeof(_i26) +\\\n",
    "sys.getsizeof(_i27) +\\\n",
    "sys.getsizeof(_i28) +\\\n",
    "sys.getsizeof(_i29) +\\\n",
    "sys.getsizeof(_i3) +\\\n",
    "sys.getsizeof(_i30) +\\\n",
    "sys.getsizeof(_i31) +\\\n",
    "sys.getsizeof(_i32) +\\\n",
    "sys.getsizeof(_i33) +\\\n",
    "sys.getsizeof(_i34) +\\\n",
    "sys.getsizeof(_i35) +\\\n",
    "sys.getsizeof(_i36) +\\\n",
    "sys.getsizeof(_i37) +\\\n",
    "sys.getsizeof(_i38) +\\\n",
    "sys.getsizeof(_i39) +\\\n",
    "sys.getsizeof(_i4) +\\\n",
    "sys.getsizeof(_i40) +\\\n",
    "sys.getsizeof(_i41) +\\\n",
    "sys.getsizeof(_i42) +\\\n",
    "sys.getsizeof(_i43) +\\\n",
    "sys.getsizeof(_i44) +\\\n",
    "sys.getsizeof(_i45) +\\\n",
    "sys.getsizeof(_i46) +\\\n",
    "sys.getsizeof(_i47) +\\\n",
    "sys.getsizeof(_i48) +\\\n",
    "sys.getsizeof(_i49) +\\\n",
    "sys.getsizeof(_i5) +\\\n",
    "sys.getsizeof(_i50) +\\\n",
    "sys.getsizeof(_i51) +\\\n",
    "sys.getsizeof(_i52) +\\\n",
    "sys.getsizeof(_i53) +\\\n",
    "sys.getsizeof(_i54) +\\\n",
    "sys.getsizeof(_i55) +\\\n",
    "sys.getsizeof(_i56) +\\\n",
    "sys.getsizeof(_i57) +\\\n",
    "sys.getsizeof(_i58) +\\\n",
    "sys.getsizeof(_i59) +\\\n",
    "sys.getsizeof(_i6) +\\\n",
    "sys.getsizeof(_i60) +\\\n",
    "sys.getsizeof(_i61) +\\\n",
    "sys.getsizeof(_i62) +\\\n",
    "sys.getsizeof(_i63) +\\\n",
    "sys.getsizeof(_i64) +\\\n",
    "sys.getsizeof(_i65) +\\\n",
    "sys.getsizeof(_i66) +\\\n",
    "sys.getsizeof(_i7) +\\\n",
    "sys.getsizeof(_i8) +\\\n",
    "sys.getsizeof(_i9) +\\\n",
    "sys.getsizeof(_ih) +\\\n",
    "sys.getsizeof(_ii) +\\\n",
    "sys.getsizeof(_iii) +\\\n",
    "sys.getsizeof(_oh) +\\\n",
    "sys.getsizeof(array) +\\\n",
    "sys.getsizeof(batch_size) +\\\n",
    "sys.getsizeof(best_score) +\\\n",
    "sys.getsizeof(best_weights) +\\\n",
    "sys.getsizeof(constants) +\\\n",
    "sys.getsizeof(datetime) +\\\n",
    "sys.getsizeof(deque) +\\\n",
    "sys.getsizeof(discount_rate) +\\\n",
    "sys.getsizeof(done) +\\\n",
    "sys.getsizeof(env) +\\\n",
    "sys.getsizeof(episode) +\\\n",
    "sys.getsizeof(epsilon) +\\\n",
    "sys.getsizeof(epsilon_greedy_policy) +\\\n",
    "sys.getsizeof(exit) +\\\n",
    "sys.getsizeof(game_over_reason) +\\\n",
    "sys.getsizeof(get_ipython) +\\\n",
    "sys.getsizeof(i) +\\\n",
    "sys.getsizeof(input_shape) +\\\n",
    "sys.getsizeof(json) +\\\n",
    "sys.getsizeof(keras) +\\\n",
    "sys.getsizeof(loss_fn) +\\\n",
    "sys.getsizeof(mapID) +\\\n",
    "sys.getsizeof(math) +\\\n",
    "sys.getsizeof(max_replay_len) +\\\n",
    "sys.getsizeof(model) +\\\n",
    "sys.getsizeof(model_from_json) +\\\n",
    "sys.getsizeof(n_episodes) +\\\n",
    "sys.getsizeof(n_epsilon_decay) +\\\n",
    "sys.getsizeof(n_max_steps) +\\\n",
    "sys.getsizeof(n_outputs) +\\\n",
    "sys.getsizeof(np) +\\\n",
    "sys.getsizeof(obs) +\\\n",
    "sys.getsizeof(optimizer) +\\\n",
    "sys.getsizeof(optimizers) +\\\n",
    "sys.getsizeof(os) +\\\n",
    "sys.getsizeof(play_one_step) +\\\n",
    "sys.getsizeof(posID_x) +\\\n",
    "sys.getsizeof(posID_y) +\\\n",
    "sys.getsizeof(quit) +\\\n",
    "sys.getsizeof(random) +\\\n",
    "sys.getsizeof(randrange) +\\\n",
    "sys.getsizeof(replay_memory) +\\\n",
    "sys.getsizeof(request) +\\\n",
    "sys.getsizeof(reward) +\\\n",
    "sys.getsizeof(sample_experiences) +\\\n",
    "sys.getsizeof(score) +\\\n",
    "sys.getsizeof(scores) +\\\n",
    "sys.getsizeof(step) +\\\n",
    "sys.getsizeof(str_2_json) +\\\n",
    "sys.getsizeof(sum_reward) +\\\n",
    "sys.getsizeof(sys) +\\\n",
    "sys.getsizeof(tf) +\\\n",
    "sys.getsizeof(training_step) +\\\n",
    "sys.getsizeof(typecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Miner_Training_Colab_CodeSample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
