{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install tf-agents==0.6.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install 'gym==0.10.11'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tf_agents\n",
    "tf_agents.__version__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install tf-agents=="
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftfy                           5.7       \n",
      "tensorflow                     2.1.0     \n",
      "tensorflow-addons              0.8.3     \n",
      "tensorflow-data-validation     0.21.5    \n",
      "tensorflow-datasets            2.1.0     \n",
      "tensorflow-estimator           2.1.0     \n",
      "tensorflow-gpu                 2.0.0     \n",
      "tensorflow-hub                 0.7.0     \n",
      "tensorflow-metadata            0.23.0    \n",
      "tensorflow-model-analysis      0.21.6    \n",
      "tensorflow-probability         0.9.0     \n",
      "tensorflow-serving-api         2.1.0     \n",
      "tensorflow-transform           0.21.2    \n",
      "tf-agents                      0.3.0     \n",
      "tfx                            0.21.2    \n",
      "tfx-bsl                        0.21.4    \n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"tf|tensorflow\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_spec.BoundedArraySpec is tf_agents.specs.BoundedArraySpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrong `shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "    self._observation_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "\n",
    "  def action_spec(self):\n",
    "    return self._action_spec\n",
    "\n",
    "  def observation_spec(self):\n",
    "    return self._observation_spec\n",
    "\n",
    "  def _reset(self):\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "    return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "  def _step(self, action):\n",
    "\n",
    "    if self._episode_ended:\n",
    "      # The last action ended the episode. Ignore the current action and start\n",
    "      # a new episode.\n",
    "      return self.reset()\n",
    "\n",
    "    # Make sure episodes don't go on forever.\n",
    "    if action == 1:\n",
    "      self._episode_ended = True\n",
    "    elif action == 0:\n",
    "      new_card = np.random.randint(1, 11)\n",
    "      self._state += new_card\n",
    "    else:\n",
    "      raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "    if self._episode_ended or self._state >= 21:\n",
    "      reward = self._state - 21 if self._state <= 21 else -21\n",
    "      # This is the only place going wrong\n",
    "      return ts.termination(np.array(self._state, dtype=np.int32), reward)\n",
    "    else:\n",
    "      return ts.transition(\n",
    "          np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why no error? Let's first make one more intentional mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "    self._observation_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "\n",
    "  def action_spec(self):\n",
    "    return self._action_spec\n",
    "\n",
    "  def observation_spec(self):\n",
    "    return self._observation_spec\n",
    "\n",
    "  def _reset(self):\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "    return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "  def _step(self, action):\n",
    "\n",
    "    if self._episode_ended:\n",
    "      # The last action ended the episode. Ignore the current action and start\n",
    "      # a new episode.\n",
    "      return self.reset()\n",
    "\n",
    "    # Make sure episodes don't go on forever.\n",
    "    if action == 1:\n",
    "      self._episode_ended = True\n",
    "    elif action == 0:\n",
    "      new_card = np.random.randint(1, 11)\n",
    "      self._state += new_card\n",
    "    else:\n",
    "      raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "    if self._episode_ended or self._state >= 21:\n",
    "      reward = self._state - 21 if self._state <= 21 else -21\n",
    "      # This is the only place going wrong\n",
    "      return ts.termination(np.array(self._state, dtype=np.int32), reward)\n",
    "    else:\n",
    "      return ts.transition(\n",
    "          np.array(self._state, dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Given `time_step`: TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(5, dtype=int32)) does not match expected `time_step_spec`: TimeStep(step_type=ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'), reward=ArraySpec(shape=(), dtype=dtype('float32'), name='reward'), discount=BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0), observation=BoundedArraySpec(shape=(1,), dtype=dtype('int32'), name='observation', minimum=0, maximum=2147483647))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-43fcc2ef6a6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menvironment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCardGameEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_py_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/rlcomp2020-tf2/lib/python3.6/site-packages/tf_agents/environments/utils.py\u001b[0m in \u001b[0;36mvalidate_py_environment\u001b[0;34m(environment, episodes)\u001b[0m\n\u001b[1;32m     65\u001b[0m       raise ValueError(\n\u001b[1;32m     66\u001b[0m           \u001b[0;34m'Given `time_step`: %r does not match expected `time_step_spec`: %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m           (time_step, time_step_spec))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Given `time_step`: TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(5, dtype=int32)) does not match expected `time_step_spec`: TimeStep(step_type=ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'), reward=ArraySpec(shape=(), dtype=dtype('float32'), name='reward'), discount=BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0), observation=BoundedArraySpec(shape=(1,), dtype=dtype('int32'), name='observation', minimum=0, maximum=2147483647))"
     ]
    }
   ],
   "source": [
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the \"**correct**\" code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "    self._observation_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "\n",
    "  def action_spec(self):\n",
    "    return self._action_spec\n",
    "\n",
    "  def observation_spec(self):\n",
    "    return self._observation_spec\n",
    "\n",
    "  def _reset(self):\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "    return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "  def _step(self, action):\n",
    "\n",
    "    if self._episode_ended:\n",
    "      # The last action ended the episode. Ignore the current action and start\n",
    "      # a new episode.\n",
    "      return self.reset()\n",
    "\n",
    "    # Make sure episodes don't go on forever.\n",
    "    if action == 1:\n",
    "      self._episode_ended = True\n",
    "    elif action == 0:\n",
    "      new_card = np.random.randint(1, 11)\n",
    "      self._state += new_card\n",
    "    else:\n",
    "      raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "    if self._episode_ended or self._state >= 21:\n",
    "      reward = self._state - 21 if self._state <= 21 else -21\n",
    "      return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "    else:\n",
    "      return ts.transition(\n",
    "          np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([0], dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([9], dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([19], dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array([23], dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array([23], dtype=int32))\n",
      "Final Reward =  -42.0\n"
     ]
    }
   ],
   "source": [
    "get_new_card_action = np.array(0, dtype=np.int32)\n",
    "end_round_action = np.array(1, dtype=np.int32)\n",
    "\n",
    "environment = CardGameEnv()\n",
    "time_step = environment.reset()\n",
    "print(time_step)\n",
    "cumulative_reward = time_step.reward\n",
    "\n",
    "for _ in range(3):\n",
    "  time_step = environment.step(get_new_card_action)\n",
    "  print(time_step)\n",
    "  cumulative_reward += time_step.reward\n",
    "\n",
    "time_step = environment.step(end_round_action)\n",
    "print(time_step)\n",
    "cumulative_reward += time_step.reward\n",
    "print('Final Reward = ', cumulative_reward)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([0], dtype=int32))\n",
    "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([9], dtype=int32))\n",
    "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([19], dtype=int32))\n",
    "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array([23], dtype=int32))\n",
    "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array([23], dtype=int32))\n",
    "Final Reward =  -42.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think this is correct: `-42.0`\n",
    "Let's oberve more extreme cases by making the same game longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([0], dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(2, dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(5, dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(12, dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(13, dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(18, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(25, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(35, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(39, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(43, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(47, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(47, dtype=int32))\n",
      "Final Reward =  -126.0\n"
     ]
    }
   ],
   "source": [
    "get_new_card_action = np.array(0, dtype=np.int32)\n",
    "end_round_action = np.array(1, dtype=np.int32)\n",
    "\n",
    "environment = CardGameEnv()\n",
    "time_step = environment.reset()\n",
    "print(time_step)\n",
    "cumulative_reward = time_step.reward\n",
    "\n",
    "for _ in range(10):\n",
    "  time_step = environment.step(get_new_card_action)\n",
    "  print(time_step)\n",
    "  cumulative_reward += time_step.reward\n",
    "\n",
    "time_step = environment.step(end_round_action)\n",
    "print(time_step)\n",
    "cumulative_reward += time_step.reward\n",
    "print('Final Reward = ', cumulative_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Well, this kind of `cumulated_reward` might serve as a mechanism to stimulate the agent to learn faster.\n",
    "- You may want to challenge yourself to write an similar environment in which the `cumulated_reward` is always `-21`, no matter how far and how many times the cards in your hands go beyond `21`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._action_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "    self._observation_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "\n",
    "  def action_spec(self):\n",
    "    return self._action_spec\n",
    "\n",
    "  def observation_spec(self):\n",
    "    return self._observation_spec\n",
    "\n",
    "  def _reset(self):\n",
    "    self._state = 0\n",
    "    self._episode_ended = False\n",
    "    return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "  def _step(self, action):\n",
    "\n",
    "    if self._episode_ended:\n",
    "      # The last action ended the episode. Ignore the current action and start\n",
    "      # a new episode.\n",
    "      return self.reset()\n",
    "\n",
    "    # Make sure episodes don't go on forever.\n",
    "    if action == 1:\n",
    "      self._episode_ended = True\n",
    "    elif action == 0:\n",
    "      new_card = np.random.randint(1, 11)\n",
    "      self._state += new_card\n",
    "    else:\n",
    "      raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "    if self._episode_ended or self._state >= 21:\n",
    "      reward = self._state - 21 if self._state <= 21 else -21\n",
    "      return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "    else:\n",
    "      return ts.transition(\n",
    "          np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "environment = CardGameEnv()\n",
    "time_step = environment.reset()\n",
    "print(type(time_step.step_type))\n",
    "print(time_step.step_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(6, dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(8, dtype=int32))\n",
      "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array(18, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(22, dtype=int32))\n",
      "Final Reward =  -42.0\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(29, dtype=int32))\n",
      "Final Reward =  -84.0\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(35, dtype=int32))\n",
      "Final Reward =  -126.0\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(45, dtype=int32))\n",
      "Final Reward =  -168.0\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(48, dtype=int32))\n",
      "Final Reward =  -210.0\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(57, dtype=int32))\n",
      "Final Reward =  -252.0\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(64, dtype=int32))\n",
      "TimeStep(step_type=array(2, dtype=int32), reward=array(-21., dtype=float32), discount=array(0., dtype=float32), observation=array(64, dtype=int32))\n",
      "Final Reward =  -294.0\n"
     ]
    }
   ],
   "source": [
    "get_new_card_action = np.array(0, dtype=np.int32)\n",
    "end_round_action = np.array(1, dtype=np.int32)\n",
    "\n",
    "environment = CardGameEnv()\n",
    "time_step = environment.reset()\n",
    "print(type(time_step.step_type))\n",
    "cumulative_reward = time_step.reward\n",
    "\n",
    "for _ in range(10):\n",
    "  if time_step.step_type == np.array([2]):\n",
    "    cumulative_reward += time_step.reward\n",
    "    print('Final Reward = ', cumulative_reward)\n",
    "  time_step = environment.step(get_new_card_action)\n",
    "  print(time_step)\n",
    "  cumulative_reward += time_step.reward\n",
    "else:\n",
    "  time_step = environment.step(end_round_action)\n",
    "  print(time_step)\n",
    "  cumulative_reward += time_step.reward\n",
    "  print('Final Reward = ', cumulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from viz_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#import pandas as pd\n",
    "import datetime\n",
    "import json\n",
    "from array import *\n",
    "import os\n",
    "import math\n",
    "from random import randrange\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes in GAME_SOCKET_DUMMY.py\n",
    "class ObstacleInfo:\n",
    "    # initial energy for obstacles: Land (key = 0): -1, Forest(key = -1): 0 (random), Trap(key = -2): -10, Swamp (key = -3): -5\n",
    "    types = {0: -1, -1: 0, -2: -10, -3: -5}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.type = 0\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.value = 0\n",
    "        \n",
    "class GoldInfo:\n",
    "    def __init__(self):\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.amount = 0\n",
    "\n",
    "    def loads(self, data):\n",
    "        golds = []\n",
    "        for gd in data:\n",
    "            g = GoldInfo()\n",
    "            g.posx = gd[\"posx\"]\n",
    "            g.posy = gd[\"posy\"]\n",
    "            g.amount = gd[\"amount\"]\n",
    "            golds.append(g)\n",
    "        return golds\n",
    "\n",
    "class PlayerInfo:\n",
    "    STATUS_PLAYING = 0\n",
    "    STATUS_ELIMINATED_WENT_OUT_MAP = 1\n",
    "    STATUS_ELIMINATED_OUT_OF_ENERGY = 2\n",
    "    STATUS_ELIMINATED_INVALID_ACTION = 3\n",
    "    STATUS_STOP_EMPTY_GOLD = 4\n",
    "    STATUS_STOP_END_STEP = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.playerId = id\n",
    "        self.score = 0\n",
    "        self.energy = 0\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.lastAction = -1\n",
    "        self.status = PlayerInfo.STATUS_PLAYING\n",
    "        self.freeCount = 0\n",
    "\n",
    "class GameInfo:\n",
    "    def __init__(self):\n",
    "        self.numberOfPlayers = 1\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.steps = 100\n",
    "        self.golds = []\n",
    "        self.obstacles = []\n",
    "\n",
    "    def loads(self, data):\n",
    "        m = GameInfo()\n",
    "        m.width = data[\"width\"]\n",
    "        m.height = data[\"height\"]\n",
    "        m.golds = GoldInfo().loads(data[\"golds\"])\n",
    "        m.obstacles = data[\"obstacles\"]\n",
    "        m.numberOfPlayers = data[\"numberOfPlayers\"]\n",
    "        m.steps = data[\"steps\"]\n",
    "        return m\n",
    "\n",
    "class UserMatch:\n",
    "    def __init__(self):\n",
    "        self.playerId = 1\n",
    "        self.posx = 0\n",
    "        self.posy = 0\n",
    "        self.energy = 50\n",
    "        self.gameinfo = GameInfo()\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n",
    "\n",
    "class StepState:\n",
    "    def __init__(self):\n",
    "        self.players = []\n",
    "        self.golds = []\n",
    "        self.changedObstacles = []\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps(self, default=lambda o: o.__dict__, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main class in GAME_SOCKET_DUMMY.py\n",
    "class GameSocket:\n",
    "    bog_energy_chain = {-5: -20, -20: -40, -40: -100, -100: -100}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stepCount = 0\n",
    "        self.maxStep = 0\n",
    "        self.mapdir = \"Maps\"  # where to load all pre-defined maps\n",
    "        self.mapid = \"\"\n",
    "        self.userMatch = UserMatch()\n",
    "        self.user = PlayerInfo(1)\n",
    "        self.stepState = StepState()\n",
    "        self.maps = {}  # key: map file name, value: file content\n",
    "        self.map = []  # running map info: 0->Land, -1->Forest, -2->Trap, -3:Swamp, >0:Gold\n",
    "        self.energyOnMap = []  # self.energyOnMap[x][y]: <0, amount of energy which player will consume if it move into (x,y)\n",
    "        self.E = 50\n",
    "        self.resetFlag = True\n",
    "        self.craftUsers = []  # players that craft at current step - for calculating amount of gold\n",
    "        self.bots = []\n",
    "        self.craftMap = {}  # cells that players craft at current step, key: x_y, value: number of players that craft at (x,y)\n",
    "\n",
    "    def init_bots(self):\n",
    "        self.bots = [Bot1(2), Bot2(3), Bot3(4)]  # use bot1(id=2), bot2(id=3), bot3(id=4)\n",
    "        #for (bot) in self.bots:  # at the beginning, all bots will have same position, energy as player\n",
    "        for bot in self.bots:  # at the beginning, all bots will have same position, energy as player\n",
    "            bot.info.posx = self.user.posx\n",
    "            bot.info.posy = self.user.posy\n",
    "            bot.info.energy = self.user.energy\n",
    "            bot.info.lastAction = -1\n",
    "            bot.info.status = PlayerInfo.STATUS_PLAYING\n",
    "            bot.info.score = 0\n",
    "            self.stepState.players.append(bot.info)\n",
    "        self.userMatch.gameinfo.numberOfPlayers = len(self.stepState.players)\n",
    "        #print(\"numberOfPlayers: \", self.userMatch.gameinfo.numberOfPlayers)\n",
    "\n",
    "    def reset(self, requests):  # load new game by given request: [map id (filename), posx, posy, initial energy]\n",
    "        # load new map\n",
    "        self.reset_map(requests[0])\n",
    "        self.userMatch.posx = int(requests[1])\n",
    "        self.userMatch.posy = int(requests[2])\n",
    "        self.userMatch.energy = int(requests[3])\n",
    "        self.userMatch.gameinfo.steps = int(requests[4])\n",
    "        self.maxStep = self.userMatch.gameinfo.steps\n",
    "\n",
    "        # init data for players\n",
    "        self.user.posx = self.userMatch.posx  # in\n",
    "        self.user.posy = self.userMatch.posy\n",
    "        self.user.energy = self.userMatch.energy\n",
    "        self.user.status = PlayerInfo.STATUS_PLAYING\n",
    "        self.user.score = 0\n",
    "        self.stepState.players = [self.user]\n",
    "        self.E = self.userMatch.energy\n",
    "        self.resetFlag = True\n",
    "        self.init_bots()\n",
    "        self.stepCount = 0\n",
    "\n",
    "    def reset_map(self, id):  # load map info\n",
    "        self.mapId = id\n",
    "        self.map = json.loads(self.maps[self.mapId])\n",
    "        self.userMatch = self.map_info(self.map)\n",
    "        self.stepState.golds = self.userMatch.gameinfo.golds\n",
    "        self.map = json.loads(self.maps[self.mapId])\n",
    "        self.energyOnMap = json.loads(self.maps[self.mapId])\n",
    "        for x in range(len(self.map)):\n",
    "            for y in range(len(self.map[x])):\n",
    "                if self.map[x][y] > 0:  # gold\n",
    "                    self.energyOnMap[x][y] = -4\n",
    "                else:  # obstacles\n",
    "                    self.energyOnMap[x][y] = ObstacleInfo.types[self.map[x][y]]\n",
    "\n",
    "    def connect(self): # simulate player's connect request\n",
    "        print(\"Connected to server.\")\n",
    "        for mapid in range(len(Maps)):\n",
    "            filename = \"map\" + str(mapid)\n",
    "            print(\"Found: \" + filename)\n",
    "            self.maps[filename] = str(Maps[mapid])\n",
    "\n",
    "    def map_info(self, map):  # get map info\n",
    "        # print(map)\n",
    "        userMatch = UserMatch()\n",
    "        userMatch.gameinfo.height = len(map)\n",
    "        userMatch.gameinfo.width = len(map[0])\n",
    "        i = 0\n",
    "        while i < len(map):\n",
    "            j = 0\n",
    "            while j < len(map[i]):\n",
    "                if map[i][j] > 0:  # gold\n",
    "                    g = GoldInfo()\n",
    "                    g.posx = j\n",
    "                    g.posy = i\n",
    "                    g.amount = map[i][j]\n",
    "                    userMatch.gameinfo.golds.append(g)\n",
    "                else:  # obstacles\n",
    "                    o = ObstacleInfo()\n",
    "                    o.posx = j\n",
    "                    o.posy = i\n",
    "                    o.type = -map[i][j]\n",
    "                    o.value = ObstacleInfo.types[map[i][j]]\n",
    "                    userMatch.gameinfo.obstacles.append(o)\n",
    "                j += 1\n",
    "            i += 1\n",
    "        return userMatch\n",
    "\n",
    "    def receive(self):  # send data to player (simulate player's receive request)\n",
    "        if self.resetFlag:  # for the first time -> send game info\n",
    "            self.resetFlag = False\n",
    "            data = self.userMatch.to_json()\n",
    "            for (bot) in self.bots:\n",
    "                bot.new_game(data)\n",
    "            # print(data)\n",
    "            return data\n",
    "        else:  # send step state\n",
    "            self.stepCount = self.stepCount + 1\n",
    "            if self.stepCount >= self.maxStep:\n",
    "                for player in self.stepState.players:\n",
    "                    player.status = PlayerInfo.STATUS_STOP_END_STEP\n",
    "            data = self.stepState.to_json()\n",
    "            #for (bot) in self.bots:  # update bots' state\n",
    "            for bot in self.bots:  # update bots' state\n",
    "                bot.new_state(data)\n",
    "            # print(data)\n",
    "            return data\n",
    "\n",
    "    def send(self, message):  # receive message from player (simulate send request from player)\n",
    "        if message.isnumeric():  # player send action\n",
    "            self.resetFlag = False\n",
    "            self.stepState.changedObstacles = []\n",
    "            action = int(message)\n",
    "            # print(\"Action = \", action)\n",
    "            self.user.lastAction = action\n",
    "            self.craftUsers = []\n",
    "            self.step_action(self.user, action)\n",
    "            for bot in self.bots:\n",
    "                if bot.info.status == PlayerInfo.STATUS_PLAYING:\n",
    "                    action = bot.next_action()\n",
    "                    bot.info.lastAction = action\n",
    "                    # print(\"Bot Action: \", action)\n",
    "                    self.step_action(bot.info, action)\n",
    "            self.action_5_craft()\n",
    "            for c in self.stepState.changedObstacles:\n",
    "                self.map[c[\"posy\"]][c[\"posx\"]] = -c[\"type\"]\n",
    "                self.energyOnMap[c[\"posy\"]][c[\"posx\"]] = c[\"value\"]\n",
    "\n",
    "        else:  # reset game\n",
    "            requests = message.split(\",\")\n",
    "            #print(\"Reset game: \", requests[:3], end='')\n",
    "            self.reset(requests)\n",
    "\n",
    "    def step_action(self, user, action):\n",
    "        switcher = {\n",
    "            0: self.action_0_left,\n",
    "            1: self.action_1_right,\n",
    "            2: self.action_2_up,\n",
    "            3: self.action_3_down,\n",
    "            4: self.action_4_free,\n",
    "            5: self.action_5_craft_pre\n",
    "        }\n",
    "        func = switcher.get(action, self.invalidAction)\n",
    "        func(user)\n",
    "\n",
    "    def action_5_craft_pre(self, user):  # collect players who craft at current step\n",
    "        user.freeCount = 0\n",
    "        if self.map[user.posy][user.posx] <= 0:  # craft at the non-gold cell\n",
    "            user.energy -= 10\n",
    "            if user.energy <= 0:\n",
    "                user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "                user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            user.energy -= 5\n",
    "            if user.energy > 0:\n",
    "                self.craftUsers.append(user)\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                if key in self.craftMap:\n",
    "                    count = self.craftMap[key]\n",
    "                    self.craftMap[key] = count + 1\n",
    "                else:\n",
    "                    self.craftMap[key] = 1\n",
    "            else:\n",
    "                user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "                user.lastAction = 6 #eliminated\n",
    "\n",
    "    def action_0_left(self, user):  # user go left\n",
    "        user.freeCount = 0\n",
    "        user.posx = user.posx - 1\n",
    "        if user.posx < 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_1_right(self, user):  # user go right\n",
    "        user.freeCount = 0\n",
    "        user.posx = user.posx + 1\n",
    "        if user.posx >= self.userMatch.gameinfo.width:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_2_up(self, user):  # user go up\n",
    "        user.freeCount = 0\n",
    "        user.posy = user.posy - 1\n",
    "        if user.posy < 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_3_down(self, user):  # user go right\n",
    "        user.freeCount = 0\n",
    "        user.posy = user.posy + 1\n",
    "        if user.posy >= self.userMatch.gameinfo.height:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_WENT_OUT_MAP\n",
    "            user.lastAction = 6 #eliminated\n",
    "        else:\n",
    "            self.go_to_pos(user)\n",
    "\n",
    "    def action_4_free(self, user):  # user free\n",
    "        user.freeCount += 1\n",
    "        if user.freeCount == 1:\n",
    "            user.energy += int(self.E / 4)\n",
    "        elif user.freeCount == 2:\n",
    "            user.energy += int(self.E / 3)\n",
    "        elif user.freeCount == 3:\n",
    "            user.energy += int(self.E / 2)\n",
    "        else:\n",
    "            user.energy = self.E\n",
    "        if user.energy > self.E:\n",
    "            user.energy = self.E\n",
    "\n",
    "    def action_5_craft(self):\n",
    "        craftCount = len(self.craftUsers)\n",
    "        # print (\"craftCount\",craftCount)\n",
    "        if (craftCount > 0):\n",
    "            for user in self.craftUsers:\n",
    "                x = user.posx\n",
    "                y = user.posy\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                c = self.craftMap[key]\n",
    "                m = min(math.ceil(self.map[y][x] / c), 50)\n",
    "                user.score += m\n",
    "                # print (\"user\", user.playerId, m)\n",
    "            for user in self.craftUsers:\n",
    "                x = user.posx\n",
    "                y = user.posy\n",
    "                key = str(user.posx) + \"_\" + str(user.posy)\n",
    "                if key in self.craftMap:\n",
    "                    c = self.craftMap[key]\n",
    "                    del self.craftMap[key]\n",
    "                    m = min(math.ceil(self.map[y][x] / c), 50)\n",
    "                    self.map[y][x] -= m * c\n",
    "                    if self.map[y][x] < 0:\n",
    "                        self.map[y][x] = 0\n",
    "                        self.energyOnMap[y][x] = ObstacleInfo.types[0]\n",
    "                    for g in self.stepState.golds:\n",
    "                        if g.posx == x and g.posy == y:\n",
    "                            g.amount = self.map[y][x]\n",
    "                            if g.amount == 0:\n",
    "                                self.stepState.golds.remove(g)\n",
    "                                self.add_changed_obstacle(x, y, 0, ObstacleInfo.types[0])\n",
    "                                if len(self.stepState.golds) == 0:\n",
    "                                    for player in self.stepState.players:\n",
    "                                        player.status = PlayerInfo.STATUS_STOP_EMPTY_GOLD\n",
    "                            break;\n",
    "            self.craftMap = {}\n",
    "\n",
    "    def invalidAction(self, user):\n",
    "        user.status = PlayerInfo.STATUS_ELIMINATED_INVALID_ACTION\n",
    "        user.lastAction = 6 #eliminated\n",
    "\n",
    "    def go_to_pos(self, user):  # player move to cell(x,y)\n",
    "        if self.map[user.posy][user.posx] == -1:\n",
    "            user.energy -= randrange(16) + 5\n",
    "        elif self.map[user.posy][user.posx] == 0:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "        elif self.map[user.posy][user.posx] == -2:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "            self.add_changed_obstacle(user.posx, user.posy, 0, ObstacleInfo.types[0])\n",
    "        elif self.map[user.posy][user.posx] == -3:\n",
    "            user.energy += self.energyOnMap[user.posy][user.posx]\n",
    "            self.add_changed_obstacle(user.posx, user.posy, 3,\n",
    "                                      self.bog_energy_chain[self.energyOnMap[user.posy][user.posx]])\n",
    "        else:\n",
    "            user.energy -= 4\n",
    "        if user.energy <= 0:\n",
    "            user.status = PlayerInfo.STATUS_ELIMINATED_OUT_OF_ENERGY\n",
    "            user.lastAction = 6 #eliminated\n",
    "\n",
    "    def add_changed_obstacle(self, x, y, t, v):\n",
    "        added = False\n",
    "        for o in self.stepState.changedObstacles:\n",
    "            if o[\"posx\"] == x and o[\"posy\"] == y:\n",
    "                added = True\n",
    "                break\n",
    "        if added == False:\n",
    "            o = {}\n",
    "            o[\"posx\"] = x\n",
    "            o[\"posy\"] = y\n",
    "            o[\"type\"] = t\n",
    "            o[\"value\"] = v\n",
    "            self.stepState.changedObstacles.append(o)\n",
    "\n",
    "    def close(self):\n",
    "        print(\"Close socket.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot1\n",
    "class Bot1:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "        \n",
    "    def get_state(self):\n",
    "        view = np.zeros([self.state.mapInfo.max_y + 1, self.state.mapInfo.max_x + 1], dtype=int)\n",
    "        for x in range(self.state.mapInfo.max_x + 1):\n",
    "            for y in range(self.state.mapInfo.max_y + 1):\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TreeID:  # Tree\n",
    "                    view[y, x] = -TreeID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TrapID:  # Trap\n",
    "                    view[y, x] = -TrapID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == SwampID: # Swamp\n",
    "                    view[y, x] = -SwampID\n",
    "                if self.state.mapInfo.gold_amount(x, y) > 0:\n",
    "                    view[y, x] = self.state.mapInfo.gold_amount(x, y)\n",
    "\n",
    "        DQNState = view.flatten().tolist() #Flattening the map matrix to a vector\n",
    "        \n",
    "        #DQNState.append(self.state.x)\n",
    "        #DQNState.append(self.state.y)\n",
    "        #DQNState.append(self.state.energy)\n",
    "        DQNState.append(self.info.posx)\n",
    "        DQNState.append(self.info.posy)\n",
    "        DQNState.append(self.info.energy)\n",
    "        for player in self.state.players:\n",
    "            # self.info.playerId is the id of the current bot\n",
    "            if player[\"playerId\"] != self.info.playerId:\n",
    "                DQNState.append(player[\"posx\"])\n",
    "                DQNState.append(player[\"posy\"])\n",
    "                \n",
    "        DQNState = np.array(DQNState)\n",
    "\n",
    "        return DQNState\n",
    "\n",
    "\n",
    "    def next_action(self):\n",
    "        s = self.get_state()\n",
    "        #return greedy_policy(s, how_gold=find_largest_gold) \n",
    "        return int(greedy_policy(s))\n",
    "\n",
    "    def get_score(self):\n",
    "        return [player[\"score\"] for player in minerEnv.socket.bots[1].state.players if player[\"playerId\"] == self.info.playerId][0]\n",
    "\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot2\n",
    "class Bot2:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = np.random.randint(0, 4)            \n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    def get_score(self):\n",
    "        return [player[\"score\"] for player in minerEnv.socket.bots[1].state.players if player[\"playerId\"] == self.info.playerId][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bots :bot3\n",
    "class Bot3:\n",
    "    ACTION_GO_LEFT = 0\n",
    "    ACTION_GO_RIGHT = 1\n",
    "    ACTION_GO_UP = 2\n",
    "    ACTION_GO_DOWN = 3\n",
    "    ACTION_FREE = 4\n",
    "    ACTION_CRAFT = 5\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.state = State()\n",
    "        self.info = PlayerInfo(id)\n",
    "\n",
    "    def next_action(self):\n",
    "        if self.state.mapInfo.gold_amount(self.info.posx, self.info.posy) > 0:\n",
    "            if self.info.energy >= 6:\n",
    "                return self.ACTION_CRAFT\n",
    "            else:\n",
    "                return self.ACTION_FREE\n",
    "        if self.info.energy < 5:\n",
    "            return self.ACTION_FREE\n",
    "        else:\n",
    "            action = self.ACTION_GO_LEFT\n",
    "            if self.info.posx % 2 == 0:\n",
    "                if self.info.posy < self.state.mapInfo.max_y:\n",
    "                    action = self.ACTION_GO_DOWN\n",
    "            else:\n",
    "                if self.info.posy > 0:\n",
    "                    action = self.ACTION_GO_UP\n",
    "                else:\n",
    "                    action = self.ACTION_GO_RIGHT            \n",
    "            return action\n",
    "\n",
    "    def new_game(self, data):\n",
    "        try:\n",
    "            self.state.init_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def new_state(self, data):\n",
    "        # action = self.next_action();\n",
    "        # self.socket.send(action)\n",
    "        try:\n",
    "            self.state.update_state(data)\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    def get_score(self):\n",
    "        return [player[\"score\"] for player in minerEnv.socket.bots[1].state.players if player[\"playerId\"] == self.info.playerId][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinerState.py\n",
    "def str_2_json(str):\n",
    "    return json.loads(str, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "class MapInfo:\n",
    "    def __init__(self):\n",
    "        self.max_x = 0 #Width of the map\n",
    "        self.max_y = 0 #Height of the map\n",
    "        self.golds = [] #List of the golds in the map\n",
    "        self.obstacles = []\n",
    "        self.numberOfPlayers = 0\n",
    "        self.maxStep = 0 #The maximum number of step is set for this map\n",
    "\n",
    "    def init_map(self, gameInfo):\n",
    "        #Initialize the map at the begining of each episode\n",
    "        self.max_x = gameInfo[\"width\"] - 1\n",
    "        self.max_y = gameInfo[\"height\"] - 1\n",
    "        self.golds = gameInfo[\"golds\"]\n",
    "        self.obstacles = gameInfo[\"obstacles\"]\n",
    "        self.maxStep = gameInfo[\"steps\"]\n",
    "        self.numberOfPlayers = gameInfo[\"numberOfPlayers\"]\n",
    "\n",
    "    def update(self, golds, changedObstacles):\n",
    "        #Update the map after every step\n",
    "        self.golds = golds\n",
    "        for cob in changedObstacles:\n",
    "            newOb = True\n",
    "            for ob in self.obstacles:\n",
    "                if cob[\"posx\"] == ob[\"posx\"] and cob[\"posy\"] == ob[\"posy\"]:\n",
    "                    newOb = False\n",
    "                    #print(\"cell(\", cob[\"posx\"], \",\", cob[\"posy\"], \") change type from: \", ob[\"type\"], \" -> \",\n",
    "                    #      cob[\"type\"], \" / value: \", ob[\"value\"], \" -> \", cob[\"value\"])\n",
    "                    ob[\"type\"] = cob[\"type\"]\n",
    "                    ob[\"value\"] = cob[\"value\"]\n",
    "                    break\n",
    "            if newOb:\n",
    "                self.obstacles.append(cob)\n",
    "                #print(\"new obstacle: \", cob[\"posx\"], \",\", cob[\"posy\"], \", type = \", cob[\"type\"], \", value = \",\n",
    "                #      cob[\"value\"])\n",
    "\n",
    "    def get_min_x(self):\n",
    "        return min([cell[\"posx\"] for cell in self.golds])\n",
    "\n",
    "    def get_max_x(self):\n",
    "        return max([cell[\"posx\"] for cell in self.golds])\n",
    "\n",
    "    def get_min_y(self):\n",
    "        return min([cell[\"posy\"] for cell in self.golds])\n",
    "\n",
    "    def get_max_y(self):\n",
    "        return max([cell[\"posy\"] for cell in self.golds])\n",
    "\n",
    "    def is_row_has_gold(self, y):\n",
    "        return y in [cell[\"posy\"] for cell in self.golds]\n",
    "\n",
    "    def is_column_has_gold(self, x):\n",
    "        return x in [cell[\"posx\"] for cell in self.golds]\n",
    "\n",
    "    def gold_amount(self, x, y): #Get the amount of golds at cell (x,y)\n",
    "        for cell in self.golds:\n",
    "            if x == cell[\"posx\"] and y == cell[\"posy\"]:\n",
    "                return cell[\"amount\"]\n",
    "        return 0 \n",
    "\n",
    "    def get_obstacle(self, x, y):  # Get the kind of the obstacle at cell(x,y)\n",
    "        for cell in self.obstacles:\n",
    "            if x == cell[\"posx\"] and y == cell[\"posy\"]:\n",
    "                return cell[\"type\"]\n",
    "        return -1  # No obstacle at the cell (x,y)\n",
    "\n",
    "\n",
    "class State:\n",
    "    STATUS_PLAYING = 0\n",
    "    STATUS_ELIMINATED_WENT_OUT_MAP = 1\n",
    "    STATUS_ELIMINATED_OUT_OF_ENERGY = 2\n",
    "    STATUS_ELIMINATED_INVALID_ACTION = 3\n",
    "    STATUS_STOP_EMPTY_GOLD = 4\n",
    "    STATUS_STOP_END_STEP = 5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.end = False\n",
    "        self.score = 0\n",
    "        self.lastAction = None\n",
    "        self.id = 0\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.energy = 0\n",
    "        self.mapInfo = MapInfo()\n",
    "        self.players = []\n",
    "        self.stepCount = 0\n",
    "        self.status = State.STATUS_PLAYING\n",
    "\n",
    "    def init_state(self, data): #parse data from server into object\n",
    "        game_info = str_2_json(data)\n",
    "        self.end = False\n",
    "        self.score = 0\n",
    "        self.lastAction = None\n",
    "        self.id = game_info[\"playerId\"]\n",
    "        self.x = game_info[\"posx\"]\n",
    "        self.y = game_info[\"posy\"]\n",
    "        self.energy = game_info[\"energy\"]\n",
    "        self.mapInfo.init_map(game_info[\"gameinfo\"])\n",
    "        self.stepCount = 0\n",
    "        self.status = State.STATUS_PLAYING\n",
    "        self.players = [{\"playerId\": 2, \"posx\": self.x, \"posy\": self.y},\n",
    "                        {\"playerId\": 3, \"posx\": self.x, \"posy\": self.y},\n",
    "                        {\"playerId\": 4, \"posx\": self.x, \"posy\": self.y}]\n",
    "\n",
    "    def update_state(self, data):\n",
    "        new_state = str_2_json(data)\n",
    "        for player in new_state[\"players\"]:\n",
    "            if player[\"playerId\"] == self.id:\n",
    "                self.x = player[\"posx\"]\n",
    "                self.y = player[\"posy\"]\n",
    "                self.energy = player[\"energy\"]\n",
    "                self.score = player[\"score\"]\n",
    "                self.lastAction = player[\"lastAction\"]\n",
    "                self.status = player[\"status\"]\n",
    "\n",
    "        self.mapInfo.update(new_state[\"golds\"], new_state[\"changedObstacles\"])\n",
    "        self.players = new_state[\"players\"]\n",
    "        self.stepCount = self.stepCount + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinerEnv.py\n",
    "TreeID = 1\n",
    "TrapID = 2\n",
    "SwampID = 3\n",
    "class MinerEnv:\n",
    "    def __init__(self):\n",
    "        self.socket = GameSocket()\n",
    "        self.state = State()\n",
    "        \n",
    "        self.score_pre = self.state.score#Storing the last score for designing the reward function\n",
    "\n",
    "    def start(self): #connect to server\n",
    "        self.socket.connect()\n",
    "\n",
    "    def end(self): #disconnect server\n",
    "        self.socket.close()\n",
    "\n",
    "    def send_map_info(self, request):#tell server which map to run\n",
    "        self.socket.send(request)\n",
    "\n",
    "    def reset(self): #start new game\n",
    "        try:\n",
    "            message = self.socket.receive() #receive game info from server\n",
    "            self.state.init_state(message) #init state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def step(self, action): #step process\n",
    "        self.socket.send(action) #send action to server\n",
    "        try:\n",
    "            message = self.socket.receive() #receive new state from server\n",
    "            self.state.update_state(message) #update to local state\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    # Functions are customized by client\n",
    "    def get_state(self):\n",
    "        # Building the map\n",
    "        #view = np.zeros([self.state.mapInfo.max_x + 1, self.state.mapInfo.max_y + 1], dtype=int)\n",
    "        view = np.zeros([self.state.mapInfo.max_y + 1, self.state.mapInfo.max_x + 1], dtype=int)\n",
    "        for x in range(self.state.mapInfo.max_x + 1):\n",
    "            for y in range(self.state.mapInfo.max_y + 1):\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TreeID:  # Tree\n",
    "                    view[y, x] = -TreeID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == TrapID:  # Trap\n",
    "                    view[y, x] = -TrapID\n",
    "                if self.state.mapInfo.get_obstacle(x, y) == SwampID: # Swamp\n",
    "                    view[y, x] = -SwampID\n",
    "                if self.state.mapInfo.gold_amount(x, y) > 0:\n",
    "                    view[y, x] = self.state.mapInfo.gold_amount(x, y)\n",
    "\n",
    "        DQNState = view.flatten().tolist() #Flattening the map matrix to a vector\n",
    "        \n",
    "        # Add position and energy of agent to the DQNState\n",
    "        DQNState.append(self.state.x)\n",
    "        DQNState.append(self.state.y)\n",
    "        DQNState.append(self.state.energy)\n",
    "        #Add position of bots \n",
    "        for player in self.state.players:\n",
    "            if player[\"playerId\"] != self.state.id:\n",
    "                DQNState.append(player[\"posx\"])\n",
    "                DQNState.append(player[\"posy\"])\n",
    "                \n",
    "        #Convert the DQNState from list to array for training\n",
    "        DQNState = np.array(DQNState)\n",
    "\n",
    "        return DQNState\n",
    "\n",
    "    def get_reward(self):\n",
    "        # Calculate reward\n",
    "        reward = 0\n",
    "        score_action = self.state.score - self.score_pre\n",
    "        self.score_pre = self.state.score\n",
    "        if score_action > 0:\n",
    "            #If the DQN agent crafts golds, then it should obtain a positive reward (equal score_action)\n",
    "            #reward += score_action\n",
    "            reward += score_action*5\n",
    "            \n",
    "        ##If the DQN agent crashs into obstacels (Tree, Trap, Swamp), then it should be punished by a negative reward\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == TreeID:  # Tree\n",
    "        #    reward -= TreeID\n",
    "        #if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == TrapID:  # Trap\n",
    "        #    reward -= TrapID\n",
    "        if self.state.mapInfo.get_obstacle(self.state.x, self.state.y) == SwampID:  # Swamp\n",
    "            reward -= SwampID\n",
    "            if self.state.lastAction == 4:\n",
    "                reward -= 40\n",
    "\n",
    "        # If out of the map, then the DQN agent should be punished by a larger nagative reward.\n",
    "        if self.state.status == State.STATUS_ELIMINATED_WENT_OUT_MAP:\n",
    "            #if self.state.stepCount < 50:\n",
    "            #    reward += -5*(50 - self.state.stepCount)\n",
    "            reward += -50\n",
    "            \n",
    "        #Run out of energy, then the DQN agent should be punished by a larger nagative reward.\n",
    "        if self.state.status == State.STATUS_ELIMINATED_OUT_OF_ENERGY:\n",
    "            if self.state.stepCount < 50:\n",
    "                reward += -(50 - self.state.stepCount)\n",
    "                if self.state.lastAction != 4:\n",
    "                    # 4 is taking a rest\n",
    "                    reward += -10\n",
    "        \n",
    "        # control comes to here \\implies our agent is not dead yet\n",
    "        if self.state.status == State.STATUS_PLAYING:\n",
    "            if self.state.energy >= 45 and self.state.lastAction == 4:\n",
    "                reward -= 30\n",
    "        # print (\"reward\",reward)\n",
    "        return reward\n",
    "\n",
    "    def check_terminate(self):\n",
    "        #Checking the status of the game\n",
    "        #it indicates the game ends or is playing\n",
    "        return self.state.status != State.STATUS_PLAYING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps of 1st round\n",
    "def CreateMaps():\n",
    "    map0 = [\n",
    "      [450,-2,0,-2,150,-1,0,0,0,0,-1,-2,-2,-2,0,0,0,0,150,-2,350],\n",
    "      [-2,-2,-2,-2,-1,0,-1,-1,-1,-1,-3,50,-2,-2,-2,-2,-3,-3,50,-2,-1],\n",
    "      [-2,-2,200,-2,0,-2,0,-2,-3,-3,-2,0,-3,-2,-2,150,-3,-3,0,0,50],\n",
    "      [0,-3,-3,-2,0,0,-1,0,550,-3,-2,0,0,0,-1,0,0,-1,-1,-1,-2],\n",
    "      [-2,0,0,0,-1,0,-1,50,300,-3,-2,0,-3,0,0,0,-1,-3,-3,-2,-1],\n",
    "      [-1,-3,-1,-3,0,-2,0,0,-2,-1,100,-3,0,-2,300,-3,0,-2,-3,-2,0],\n",
    "      [-2,-3,-1,-3,-1,500,-1,-3,-2,-1,0,-1,0,-1,0,-1,0,-2,-3,-3,-1],\n",
    "      [0,-3,-1,-3,0,-2,-3,-3,0,0,0,0,-2,0,-2,-3,-3,-3,-3,200,-1],\n",
    "      [1200,-3,-1,-3,-1,-1,-2,-2,0,-1,150,-2,0,-2,0,0,-2,-3,-3,1500,50],\n",
    "    ]\n",
    "    map1 = [\n",
    "      [550,-1,-1,-2,-2,-2,-2,150,0,0,0,-3,-2,400,-3,650,-2,-1,0,0,0],\n",
    "      [350,-1,-1,-2,0,0,-2,-2,-2,-1,0,-3,-3,-2,300,-2,-1,650,-2,-1,0],\n",
    "      [-1,-1,450,-2,0,0,0,0,0,0,0,0,0,-3,-3,-3,-1,-1,-3,0,0],\n",
    "      [-1,-1,-2,-2,0,-3,-2,0,0,-3,-3,-3,0,0,0,0,0,0,-3,0,150],\n",
    "      [0,0,-2,0,-3,-3,-3,0,-1,-2,400,-3,-3,0,-2,0,-1,0,-3,0,0],\n",
    "      [0,200,-2,0,-3,250,-1,0,0,-1,-2,-3,-2,0,-1,300,-1,0,-3,-1,0],\n",
    "      [-3,-3,-2,0,-3,-3,-3,0,0,0,0,-3,-3,-3,-2,-2,-2,0,-2,-2,0],\n",
    "      [-1,-3,-2,0,0,-2,0,0,-3,-3,-3,-3,150,-3,0,0,0,0,-2,200,0],\n",
    "      [800,-3,-2,-3,450,-2,0,-3,-3,200,-1,250,-1,-3,0,-1,-1,0,0,0,0],\n",
    "    ]\n",
    "    map2 = [\n",
    "      [200,-2,-2,250,-2,0,-2,-1,0,-3,500,-3,-3,0,0,0,0,0,-3,450,-3],\n",
    "      [-2,-2,-1,-2,-1,0,-3,200,-2,0,-3,0,150,0,-2,-1,0,0,0,-3,0],\n",
    "      [-3,-2,-1,-3,-1,0,0,-3,-2,0,0,0,-1,-2,450,-2,0,-2,150,-2,0],\n",
    "      [300,-3,-3,300,-2,-2,-2,-2,300,-2,-2,0,0,0,-2,0,-3,-3,-3,-2,0],\n",
    "      [-3,-3,0,-3,-1,350,-1,0,-2,-2,350,-2,0,-3,0,0,-3,300,-3,-2,250],\n",
    "      [-3,0,0,0,-1,-1,-1,-1,-3,0,-2,0,-3,400,-3,0,-3,-3,-3,0,0],\n",
    "      [450,-3,0,0,0,0,-1,400,-3,0,0,0,-2,-3,-2,0,0,0,0,0,0],\n",
    "      [-3,0,-1,0,-1,0,-3,-3,-3,0,-1,0,0,0,250,-3,-3,-3,-1,-2,-2],\n",
    "      [0,0,-1,200,-1,-3,500,-3,0,-1,200,-1,0,0,-2,-2,-2,-1,400,-1,-2],\n",
    "    ]\n",
    "    map3 = [\n",
    "      [0,-1,0,0,0,0,0,-3,0,-1,0,-1,-3,150,500,200,-1,0,-2,-1,0],\n",
    "      [-3,500,-3,-2,350,-1,0,0,0,0,0,0,-1,-1,50,-1,0,0,-2,350,-3],\n",
    "      [-1,-3,-2,0,-1,-2,0,-1,0,0,0,0,0,0,-2,-1,0,0,-2,-1,-3],\n",
    "      [0,-3,0,0,0,0,-2,600,-3,0,0,-2,-2,0,-2,0,0,0,0,0,0],\n",
    "      [0,0,0,0,-1,-1,0,-3,0,-1,400,-3,-2,0,0,0,-1,-2,-1,-1,-1],\n",
    "      [-1,0,0,-1,-3,-3,-1,-1,0,0,-3,-2,0,0,0,0,-1,700,-1,-1,-3],\n",
    "      [350,-2,-1,-3,-2,-3,-3,-1,0,-3,0,0,0,0,-3,0,-1,-1,-1,-3,200],\n",
    "      [0,-1,-3,-2,250,-2,-3,-1,0,0,0,0,-2,0,0,0,0,-1,-3,300,0],\n",
    "      [0,-3,-2,300,1000,-2,-3,-1,0,-1,0,-2,100,-2,-1,0,-1,-3,400,0,800],\n",
    "    ]\n",
    "    map4 = [\n",
    "      [0,0,0,0,0,0,0,-2,0,0,0,0,-2,0,0,0,0,-1,-1,800,-1],\n",
    "      [100,-1,-3,-2,0,0,-1,200,-1,-2,250,-2,-2,250,-1,0,0,-1,-2,-1,-2],\n",
    "      [-1,700,-1,-3,150,-1,-1,-3,-3,-2,-2,-1,-3,-2,-1,0,0,-3,0,-1,0],\n",
    "      [0,-1,-3,0,-1,0,-3,-3,-1,-3,-1,600,-1,-3,-2,-1,-3,500,-1,0,0],\n",
    "      [0,-3,0,0,0,0,-2,-1,350,-1,50,-1,-3,50,0,0,0,-1,0,0,-2],\n",
    "      [0,0,0,-3,250,-3,-3,-3,-1,500,450,-1,-3,0,-1,0,0,0,0,-2,100],\n",
    "      [0,-3,0,0,-3,0,0,0,-3,-1,-1,-3,0,0,-2,300,-2,-1,0,0,-2],\n",
    "      [0,-1,-3,-2,0,0,0,-1,0,-3,-3,-3,-1,-2,-2,-1,-2,0,-1,0,0],\n",
    "      [-1,500,-1,-3,-2,0,-1,450,-1,0,0,-1,500,-1,-2,-1,-2,0,50,0,0],\n",
    "    ]\n",
    "    Maps = (map0,map1,map2,map3,map4)\n",
    "    return Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_over_reason = (\n",
    "    \"playing\",\n",
    "    \"went_out_map\",\n",
    "    \"out_of_energy\",\n",
    "    \"invalid_action\",\n",
    "    \"no_more_gold\",\n",
    "    \"no_more_step\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_MAX_X = 21\n",
    "MAP_MAX_Y = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Maps = CreateMaps()\n",
    "minerEnv = MinerEnv()\n",
    "minerEnv.start()\n",
    "mapID = np.random.randint(0, 5)\n",
    "mapID = 1\n",
    "posID_x = np.random.randint(MAP_MAX_X) \n",
    "posID_y = np.random.randint(MAP_MAX_Y)\n",
    "\n",
    "request = (\"map\" + str(mapID) + \",\" + str(posID_x) + \",\" + str(posID_y) + \",50,100\") \n",
    "minerEnv.send_map_info(request)\n",
    "\n",
    "minerEnv.reset()\n",
    "s = minerEnv.get_state()\n",
    "carte = s[:-9].reshape(MAP_MAX_Y, MAP_MAX_X)\n",
    "carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_image = s[:n_px].reshape((height, width))\n",
    "numerical_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_golds = np.argwhere(numerical_image>0)\n",
    "pos_golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from non_RL_agent import find_closest_gold\n",
    "find_closest_gold(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "needed_displacements = [\"left\"]*2 + [\"up\"]*1 + [\"left\"]*5 + [\"up\"]*3\n",
    "needed_displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_displacements = deque(needed_displacements)\n",
    "needed_displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_displacements.remove(\"up\")\n",
    "needed_displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(needed_displacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_displacements.remove(\"up\")\n",
    "needed_displacements.remove(\"up\")\n",
    "needed_displacements.remove(\"up\")\n",
    "needed_displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(needed_displacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([].extend([2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([1].extend([2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1]\n",
    "A.extend([2,3])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "terrain_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(9).reshape((3,3))[[1,2]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.arange(9).reshape((3,3))[*[1,2]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SyntaxError: invalid syntax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.arange(9).reshape((3,3))[**[1,2]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SyntaxError: invalid syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_image = s[:n_px].reshape((height, width))\n",
    "print(f\"numerical_image =\\n{numerical_image}\")\n",
    "row_col_largest = np.argmax(numerical_image)\n",
    "print(f\"row_col_largest = {row_col_largest}\")\n",
    "row_col_largest = np.unravel_index(np.argmax(numerical_image, axis=None), numerical_image.shape)\n",
    "print(f\"row_col_largest = {row_col_largest}\")\n",
    "print(f\"max =\\n{numerical_image[row_col_largest[0], row_col_largest[1]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_col_largest[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_gold(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[n_px:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from non_RL_agent import find_largest_gold\n",
    "find_largest_gold(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from non_RL_agent import *\n",
    "# Parameters for training a DQN model\n",
    "N_EPISODES = 500\n",
    "MAX_STEP = 100   #The number of steps for each episode\n",
    "BATCH_SIZE = 32   #The number of experiences for each replay \n",
    "MEMORY_SIZE = 100_000 #The size of the batch for storing experiences\n",
    "SAVE_NETWORK = 150  # After this number of episodes, the DQN model is saved for testing later. \n",
    "INITIAL_REPLAY_SIZE = 1000 #The number of experiences are stored in the memory batch before starting replaying\n",
    "INPUT_DIMS = 198 #The number of input values for the DQN model\n",
    "N_ACTIONS = 6  #The number of actions output from the DQN model\n",
    "MAP_MAX_X = 21 #Width of the Map\n",
    "MAP_MAX_Y = 9  #Height of the Map\n",
    "\n",
    "\n",
    "Maps = CreateMaps()\n",
    "maps = [np.array(m) for m in Maps]\n",
    "minerEnv = MinerEnv()\n",
    "minerEnv.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapID = np.random.randint(0, 5)\n",
    "posID_x = np.random.randint(MAP_MAX_X) \n",
    "posID_y = np.random.randint(MAP_MAX_Y)\n",
    "request = \"map{},{},{},50,100\".format(mapID, posID_x, posID_y)\n",
    "minerEnv.send_map_info(request)\n",
    "minerEnv.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.stepCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[1].state.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[2].state.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.step(greedy_policy(s, how_gold=find_worthiest_gold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.x, minerEnv.socket.bots[0].state.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[1].state.x, minerEnv.socket.bots[1].state.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[2].state.x, minerEnv.socket.bots[2].state.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].info.posx, minerEnv.socket.bots[0].info.posy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = minerEnv.get_state()\n",
    "s[n_px:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = minerEnv.get_state()\n",
    "s[n_px:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].info.energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].info.playerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.mapInfo.golds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.mapInfo.obstacles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[1].info.playerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[1].state.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[2].state.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[2].state.stepCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[1].state.players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].state.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to get bot's score?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[player[\"score\"] for player in minerEnv.socket.bots[1].state.players if player[\"playerId\"] == self.info.playerId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerEnv.socket.bots[0].get_state()[n_px:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[n_px:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have them play with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from non_RL_agent import *\n",
    "# Parameters for training a DQN model\n",
    "N_EPISODES = 50\n",
    "MAX_STEP = 100   #The number of steps for each episode\n",
    "BATCH_SIZE = 32   #The number of experiences for each replay \n",
    "MEMORY_SIZE = 100_000 #The size of the batch for storing experiences\n",
    "SAVE_NETWORK = 150  # After this number of episodes, the DQN model is saved for testing later. \n",
    "INITIAL_REPLAY_SIZE = 1000 #The number of experiences are stored in the memory batch before starting replaying\n",
    "INPUT_DIMS = 198 #The number of input values for the DQN model\n",
    "N_ACTIONS = 6  #The number of actions output from the DQN model\n",
    "MAP_MAX_X = 21 #Width of the Map\n",
    "MAP_MAX_Y = 9  #Height of the Map\n",
    "\n",
    "\n",
    "Maps = CreateMaps()\n",
    "maps = [np.array(m) for m in Maps]\n",
    "minerEnv = MinerEnv()\n",
    "minerEnv.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapID = np.random.randint(0, 5)\n",
    "posID_x = np.random.randint(MAP_MAX_X) \n",
    "posID_y = np.random.randint(MAP_MAX_Y)\n",
    "request = \"map{},{},{},50,100\".format(mapID, posID_x, posID_y)\n",
    "minerEnv.send_map_info(request)\n",
    "minerEnv.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for episode_i in range(N_EPISODES):\n",
    "    try:\n",
    "        mapID = np.random.randint(0, 5)\n",
    "        posID_x = np.random.randint(MAP_MAX_X) \n",
    "        posID_y = np.random.randint(MAP_MAX_Y)\n",
    "\n",
    "        #request = (\"map\" + str(mapID) + \",\" + str(posID_x) + \",\" + str(posID_y) + \",50,100\") \n",
    "        request = \"map{},{},{},50,100\".format(mapID, posID_x, posID_y)\n",
    "        minerEnv.send_map_info(request)\n",
    "\n",
    "        minerEnv.reset()\n",
    "        s = minerEnv.get_state()\n",
    "        terminate = False # This indicates whether the episode has ended\n",
    "        maxStep = minerEnv.state.mapInfo.maxStep\n",
    "        for step in range(0, maxStep):\n",
    "            minerEnv.step(greedy_policy(s, how_gold=find_worthiest_gold))\n",
    "            s_next = minerEnv.get_state()\n",
    "            #reward = minerEnv.get_reward()\n",
    "            terminate = minerEnv.check_terminate()\n",
    "            s = s_next\n",
    "            \n",
    "            if terminate == True:\n",
    "                break\n",
    "\n",
    "        #print('\\n(episode {: 5d}) step {: 3d}. gold {: 4d}. {}'.format(episode_i+1, step+1, minerEnv.state.score, game_over_reason[minerEnv.state.status]), end=\"\\n\\n\")\n",
    "        print('(episode {: 5d})'.format(episode_i+1))\n",
    "        print('(agent)   gold {: 5d}/{: 4d}   step {: 4d}   die of {}'.format(minerEnv.state.score, gold_total(maps[mapID]), step+1, game_over_reason[minerEnv.state.status]))\n",
    "        print(\"(bot1)    gold {: 5d}/{: 4d}   step {: 4d}\".format(minerEnv.socket.bots[0].get_score(), gold_total(maps[mapID]), minerEnv.socket.bots[0].state.stepCount))\n",
    "        print(\"(bot2)    gold {: 5d}/{: 4d}   step {: 4d}\".format(minerEnv.socket.bots[1].get_score(), gold_total(maps[mapID]), minerEnv.socket.bots[1].state.stepCount))\n",
    "        print(\"(bot3)    gold {: 5d}/{: 4d}   step {: 4d}\".format(minerEnv.socket.bots[2].get_score(), gold_total(maps[mapID]), minerEnv.socket.bots[2].state.stepCount))\n",
    "        print()\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()                \n",
    "        #print(\"Finished.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not as good as\n",
    "the policy of finding closest gold first."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Miner_Training_Colab_CodeSample.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
